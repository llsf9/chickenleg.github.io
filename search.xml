<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Colorization using Optimization</title>
    <url>/2022/05/06/Colorization%20using%20Optimization/</url>
    <content><![CDATA[<p><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h205yxz28gj216j0dt776.jpg" alt=""></p>
<h2 id="论文概述"><a href="#论文概述" class="headerlink" title="论文概述"></a>论文概述</h2><blockquote>
<p>在本文中，我们提出了一种简单的着色方法:基于一个简单前提：时空中具有相似强度(intensity:Y)的<strong>相邻像素应该具有相似的颜色</strong>。 我们使用次成本函数形式化这个前提，并获得一个可以使用标准技术有效解决的优化问题。</p>
</blockquote>
<h3 id="目标函数"><a href="#目标函数" class="headerlink" title="目标函数"></a>目标函数</h3><p>Y可以通过gray图像作为已知信息，因此我们需要通过临近像素的推测U和V<br>MINIMIZE</p>
<script type="math/tex; mode=display">J(U) = \sum_r \left( U(r) - \sum_{s \in N(r)} w_{rs} U(s) \right)^2</script><script type="math/tex; mode=display">J(V) = \sum_r \left( V(r) - \sum_{s \in N(r)} w_{rs} V(s) \right)^2</script><ul>
<li>r: 目标像素 N(r):临近像素</li>
<li>$w_{rs}$的条件<ul>
<li>两像素间Y越相似，w越大；两像素间Y差值越大，w越小</li>
<li>和为1</li>
</ul>
</li>
</ul>
<h3 id="约束条件"><a href="#约束条件" class="headerlink" title="约束条件"></a>约束条件</h3><p>相邻像素具有相似Y时应该具有相似的U和V</p>
<h3 id="权重函数"><a href="#权重函数" class="headerlink" title="权重函数"></a>权重函数</h3><script type="math/tex; mode=display">w_{rs} \propto \exp \left( \frac{-\left(Y(r)-Y(s)\right)^2}{2 \sigma_r^2} \right)</script><ul>
<li>$\sigma_r^2$为包含r的临近像素的variance</li>
</ul>
<h2 id="实现思路"><a href="#实现思路" class="headerlink" title="实现思路"></a>实现思路</h2><ol>
<li>二乘问题的目的函数转换为解线性方程组Ax=b的问题<ul>
<li>如果按照稠密矩阵构造A就需要使用$(A^TA)^{-1}A^Tb$计算，将会十分庞大；如果用稀疏矩阵则会大大减少计算量<blockquote>
<p>呃呃搞明白以后思路就是如此简单。。。。</p>
</blockquote>
</li>
</ul>
</li>
</ol>
<h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><h3 id="import库"><a href="#import库" class="headerlink" title="import库"></a>import库</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 依赖库 </span></span><br><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> color</span><br><span class="line"><span class="keyword">from</span> scipy.sparse <span class="keyword">import</span> csr_matrix</span><br><span class="line"><span class="keyword">from</span> scipy.sparse.linalg <span class="keyword">import</span> spsolve</span><br></pre></td></tr></table></figure>
<h3 id="图像预处理"><a href="#图像预处理" class="headerlink" title="图像预处理"></a>图像预处理</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Load the images</span></span><br><span class="line"><span class="comment"># 打开图片转换为RGB再转换为YUV</span></span><br><span class="line">img_in   = color.rgb2yuv( np.array( Image.<span class="built_in">open</span>( <span class="string">&#x27;baby.png&#x27;</span> ).convert(<span class="string">&quot;RGB&quot;</span>), dtype=<span class="built_in">float</span> ) / <span class="number">255</span> )</span><br><span class="line">img_edit = color.rgb2yuv( np.array( Image.<span class="built_in">open</span>( <span class="string">&#x27;baby_marked.png&#x27;</span> ).convert(<span class="string">&quot;RGB&quot;</span>), dtype=<span class="built_in">float</span> ) / <span class="number">255</span> )</span><br><span class="line">img_hint = np.zeros( img_edit.shape )</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过图片像素相减提取hint</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line">idx = (np.<span class="built_in">abs</span>((img_in-img_edit).<span class="built_in">sum</span>(<span class="number">2</span>)) &gt; <span class="number">1e-4</span>)</span><br><span class="line">img_hint[ idx ] = img_edit[ idx ]</span><br></pre></td></tr></table></figure>
<ul>
<li><code>Image.open()</code>：返回一个image的对象(shape=(w,h))<ul>
<li><code>Image.open().convert(&quot;RGB&quot;)</code>：返回一个image的RGB对象(shape=(w,h,c))</li>
</ul>
</li>
<li><code>sum(n)</code>：沿n维的sum</li>
</ul>
<h3 id="生成稀疏矩阵A"><a href="#生成稀疏矩阵A" class="headerlink" title="生成稀疏矩阵A"></a>生成稀疏矩阵A</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Create the optimization problem</span></span><br><span class="line">w = img_edit.shape[<span class="number">0</span>]</span><br><span class="line">h = img_edit.shape[<span class="number">1</span>]</span><br><span class="line"><span class="comment"># window size</span></span><br><span class="line">wpx = <span class="number">1</span> </span><br><span class="line"><span class="comment"># u和v：只放入已确定颜色的像素id的uv值</span></span><br><span class="line">b_u = np.zeros( (w*h,) )</span><br><span class="line">b_v = b_u.copy()</span><br><span class="line"><span class="comment"># Sparse matrix，一对(row,col)代表一对邻居关系的像素，dat内存储权重</span></span><br><span class="line">row = []</span><br><span class="line">col = []</span><br><span class="line">dat = []</span><br><span class="line"></span><br><span class="line"><span class="comment"># 遍历 w * h = n</span></span><br><span class="line"><span class="keyword">for</span> v <span class="keyword">in</span> <span class="built_in">range</span>(h):</span><br><span class="line">    <span class="keyword">for</span> u <span class="keyword">in</span> <span class="built_in">range</span>(w):</span><br><span class="line">        <span class="comment"># （w，v）to index</span></span><br><span class="line">        i = v*w + u</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Add first entry U(r) for both  channels</span></span><br><span class="line">        <span class="comment"># 像素本身等于自身，因此稀疏矩阵A的对角均为1</span></span><br><span class="line">        row.append( i )</span><br><span class="line">        col.append( i )</span><br><span class="line">        dat.append( <span class="number">1.</span> )</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Skip coloured areas,</span></span><br><span class="line">        <span class="comment"># 已经在给的hint里上色的区域就跳过</span></span><br><span class="line">        <span class="keyword">if</span> idx[u,v]:</span><br><span class="line">            b_u[i] = img_edit[u,v,<span class="number">1</span>]</span><br><span class="line">            b_v[i] = img_edit[u,v,<span class="number">2</span>]</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 求r的neighbour范围</span></span><br><span class="line">        umin = <span class="built_in">max</span>(<span class="number">0</span>,u-wpx)</span><br><span class="line">        umax = <span class="built_in">min</span>(w,u+wpx+<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        vmin = <span class="built_in">max</span>(<span class="number">0</span>,v-wpx)</span><br><span class="line">        vmax = <span class="built_in">min</span>(h,v+wpx+<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 求neighbour范围内的variance</span></span><br><span class="line">        patch = img_in[ umin:umax, vmin:vmax, <span class="number">0</span> ]</span><br><span class="line">        mu_r = np.mean( patch )</span><br><span class="line">        sigma_r = np.var( patch )</span><br><span class="line">        sigma_r = <span class="built_in">max</span>( sigma_r, <span class="number">1e-6</span> )</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 求r的Y</span></span><br><span class="line">        Yr = img_in[u,v,<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Go over neighbours</span></span><br><span class="line">        <span class="comment"># 遍历neighbour，求各自的w</span></span><br><span class="line">        N = []</span><br><span class="line">        wrs = []</span><br><span class="line">        <span class="keyword">for</span> nu <span class="keyword">in</span> <span class="built_in">range</span>( umin, umax ):</span><br><span class="line">            <span class="keyword">for</span> nv <span class="keyword">in</span> <span class="built_in">range</span>( vmin, vmax ):</span><br><span class="line">                j = nv*w + nu</span><br><span class="line">                <span class="keyword">if</span> i==j:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                Ys = img_in[nu,nv,<span class="number">0</span>]</span><br><span class="line">                wrs.append(np.exp(-<span class="number">1</span>*(Yr-Ys)*(Yr-Ys)/ <span class="number">2</span> / sigma_r))</span><br><span class="line">                N.append(j)</span><br><span class="line">        wrs = np.array( wrs )</span><br><span class="line">        <span class="comment"># 对w的约束条件：和必须为1</span></span><br><span class="line">        wrs /= wrs.<span class="built_in">sum</span>()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 根据求出的w完善矩阵</span></span><br><span class="line">        <span class="keyword">for</span> k,j <span class="keyword">in</span> <span class="built_in">enumerate</span>(N):</span><br><span class="line">            row.append(i)</span><br><span class="line">            col.append(j)</span><br><span class="line">            dat.append(-wrs[k])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 最终生成一个大小为(wh,wh)的，包含所有点与点之间的权重的矩阵</span></span><br><span class="line">A = csr_matrix( (dat, (row,col)) )</span><br></pre></td></tr></table></figure>
<ul>
<li><code>csr_matrix( (data, (row_index,col_index)) )</code>:  <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">csr_matrix( ([<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>], ([<span class="number">1</span>,<span class="number">3</span>,<span class="number">3</span>],[<span class="number">0</span>,<span class="number">1</span>,<span class="number">3</span>])) ).toarray()</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>array([[<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">   [<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">   [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">   [<span class="number">0</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>]], dtype=int64)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="解方程组生成目标图像"><a href="#解方程组生成目标图像" class="headerlink" title="解方程组生成目标图像"></a>解方程组生成目标图像</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Solve the optimization and display results</span></span><br><span class="line">Y = img_in[:,:,<span class="number">0</span>:<span class="number">1</span>]</span><br><span class="line">U = spsolve(A, b_u).reshape( h, w, <span class="number">1</span> ).transpose( (<span class="number">1</span>,<span class="number">0</span>,<span class="number">2</span>) )</span><br><span class="line">V = spsolve(A, b_v).reshape( h, w, <span class="number">1</span> ).transpose( (<span class="number">1</span>,<span class="number">0</span>,<span class="number">2</span>) )</span><br><span class="line"></span><br><span class="line">img_out = np.concatenate( (Y,U,V), axis=<span class="number">2</span> )</span><br><span class="line">plt.imshow( color.yuv2rgb(img_out) )</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>study</category>
      </categories>
      <tags>
        <tag>optimization</tag>
      </tags>
  </entry>
  <entry>
    <title>HexoTags</title>
    <url>/2022/05/05/HexoTags/</url>
    <content><![CDATA[<h2 id="Note"><a href="#Note" class="headerlink" title="Note"></a>Note</h2><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">&#123;% note [class]%&#125;</span><br><span class="line">Any content (support inline tags too.io).</span><br><span class="line">&#123;% endnote %&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>空白</li>
<li>default</li>
<li>primary</li>
<li>success</li>
<li>info</li>
<li>warning</li>
<li>danger</li>
</ul>
<h2 id="Mermaid"><a href="#Mermaid" class="headerlink" title="Mermaid"></a>Mermaid</h2><div class="note modern"><p>使用mermaid标籤可以绘製Flowchart（流程图）、Sequence diagram（时序图 ）、Class Diagram（类别图）、State Diagram（状态图）、Gantt（甘特图）和Pie Chart（圆形图），具体可以查看<a href="https://mermaid-js.github.io/mermaid/#/">Mermaide文档</a></p>
</div>
<h2 id="Tabs"><a href="#Tabs" class="headerlink" title="Tabs"></a>Tabs</h2><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">&#123;% tabs test1 %&#125;</span><br><span class="line">&lt;!-- tab --&gt;</span><br><span class="line"><span class="strong">**This is Tab 1.**</span></span><br><span class="line">&lt;!-- endtab --&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- tab --&gt;</span><br><span class="line"><span class="strong">**This is Tab 2.**</span></span><br><span class="line">&lt;!-- endtab --&gt;</span><br></pre></td></tr></table></figure>
<div class="tabs" id="test1"><ul class="nav-tabs"><li class="tab active"><button type="button" data-href="#test1-1">表格1</button></li><li class="tab"><button type="button" data-href="#test1-2">表格2</button></li></ul><div class="tab-contents"><div class="tab-item-content active" id="test1-1"><p>这是1</p><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="test1-2"><p>这是2</p><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div></div></div>
<h2 id="label"><a href="#label" class="headerlink" title="label"></a>label</h2><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">&#123;% label 我是 %&#125;&#123;% label 什么 blue %&#125;&#123;%label 颜色 red %&#125;</span><br></pre></td></tr></table></figure>
<mark class="hl-label default">我是</mark> <mark class="hl-label blue">什么</mark> <mark class="hl-label red">颜色</mark> 
]]></content>
      <categories>
        <category>study</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>PRML</title>
    <url>/2022/05/05/PRML/</url>
    <content><![CDATA[<h1 id="Pattern-recognition-and-machine-learning"><a href="#Pattern-recognition-and-machine-learning" class="headerlink" title="Pattern recognition and machine learning"></a>Pattern recognition and machine learning</h1><h2 id="0-Guidance"><a href="#0-Guidance" class="headerlink" title="0. Guidance"></a>0. Guidance</h2><ul>
<li>English<ol>
<li>neural network  </li>
<li>in the past decade</li>
<li>achieve breakthrough　取得重大进展</li>
<li>speech recognition 语音识别</li>
<li>machine translation 机器翻译</li>
<li>train CNN from scratch 从零开始训练</li>
<li>afterwards 之后</li>
<li>ambiguous 不明确的</li>
<li>classes to be recognized 将要被识别的类</li>
<li>estimate 评价</li>
<li>supplemental 补充的</li>
<li>proceed 继续</li>
</ol>
</li>
</ul>
<h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h2><ul>
<li>English<ol>
<li>contribute to 造成；以助于</li>
<li>emphasize 强调</li>
<li>tough 难的</li>
<li>facility 能力</li>
<li>prebuilt 做好的</li>
</ol>
</li>
</ul>
<blockquote>
<p>Perceptual computing in auttumn is advanced content of RP</p>
</blockquote>
<h3 id="1-1-what-is-PR"><a href="#1-1-what-is-PR" class="headerlink" title="1.1 what is PR"></a>1.1 what is PR</h3><ul>
<li>Problem/target of PR:<strong>How to estimate the class of data?</strong></li>
<li><p>Method / Procedure of PR</p>
<ol>
<li>prepare training data(labeled)</li>
<li>get feature vectors from data</li>
<li>get distribution of each class from feature vectors</li>
<li>get distribution of each class</li>
<li>define class boudary </li>
<li><p>estimate class</p>
<p>❓What is difference between PR and classification</p>
</li>
</ol>
<ul>
<li><p>Pattern recognition is a generic term for the ability to recognize regularities or patterns in data. A more generic one is machine learning. Classification is an example of pattern recognition, where a model devides the data into classes.</p>
<p>  More specific from left to right: <strong><em>Machine Learning &gt; Pattern Recognition &gt; Classification &gt; Linear Classification &gt; SVM</em></strong></p>
</li>
</ul>
</li>
</ul>
<h3 id="SV1-2-Data-driven-feature-extraction"><a href="#SV1-2-Data-driven-feature-extraction" class="headerlink" title="SV1-2 Data-driven feature extraction"></a>SV1-2 Data-driven feature extraction</h3><ul>
<li>English<ol>
<li>wind turbine 风轮机</li>
<li>anomaly detection 异常检出</li>
<li>large- scale 大规模的</li>
<li>feasible 可能的，可行的 《=》 infeasible</li>
<li>adhoc video search 特别录像查询（whether the queried object is shown in video or not）</li>
<li>-driven 由…主导的<ol>
<li>data-driven 数据驱动的</li>
</ol>
</li>
<li>discriminative model 識別モデル</li>
<li>be suitable to 适合于</li>
<li>CMS：Condition Monitoring System</li>
<li>GMM:Gaussian Mixture Model</li>
<li></li>
</ol>
</li>
<li>If we don’t have enough data to train a network when we know it’s similar to another task, we can:  use the <strong>well-developed NN for feature extractor    →</strong> so we can only trian <strong>a part of NN by fewer train data</strong></li>
<li><p>Anomaly  detection APPROACH</p>
<ol>
<li><p>Auto encoder (AE)</p>
<blockquote>
<p>エンコードしてからデコードします　→　次元削減、特徴抽出</p>
<ul>
<li>教師なし学習、異常データいらない</li>
<li>仕組み：デコードの時に再構築するため、学習されていないものが元画像とのlossがめちゃくちゃ高くなり、Acnomalyと判定される。<a href="http://www.renom.jp/ja/notebooks/tutorial/clustering/anomaly-detection-using-autoencoder/notebook.html">http://www.renom.jp/ja/notebooks/tutorial/clustering/anomaly-detection-using-autoencoder/notebook.html</a></li>
<li>Need a great number of Traing DATASET</li>
</ul>
</blockquote>
<pre><code> ![截屏2022-04-06 15.31.18.png](Pattern%20recognition%20and%20machine%20learning%20e1f94fd17812467f8adc1a323302ed35/%E6%88%AA%E5%B1%8F2022-04-06_15.31.18.png)

 ![截屏2022-04-06 15.33.26.png](Pattern%20recognition%20and%20machine%20learning%20e1f94fd17812467f8adc1a323302ed35/%E6%88%AA%E5%B1%8F2022-04-06_15.33.26.png)
</code></pre></li>
<li><p>DNN (discriminative feature extractor)</p>
<ul>
<li><p>need to input <strong>normal data and abnoormal data</strong> to train the model how to discriminate</p>
<p>  <img src="Pattern%20recognition%20and%20machine%20learning%20e1f94fd17812467f8adc1a323302ed35/%E6%88%AA%E5%B1%8F2022-04-06_15.33.00.png" alt="截屏2022-04-06 15.33.00.png"></p>
<p>  <img src="Pattern%20recognition%20and%20machine%20learning%20e1f94fd17812467f8adc1a323302ed35/%E6%88%AA%E5%B1%8F2022-04-06_15.33.37.png" alt="截屏2022-04-06 15.33.37.png"></p>
</li>
</ul>
</li>
</ol>
</li>
</ul>
<h3 id="SV2-Semi-supervised-learning"><a href="#SV2-Semi-supervised-learning" class="headerlink" title="SV2 Semi-supervised learning"></a>SV2 Semi-supervised learning</h3><ul>
<li>English<ul>
<li>assign labels ラベルを付与する</li>
<li>supervised 教師あり</li>
<li>semi-supervised 半教師あり</li>
<li>unsupervised 教師なし</li>
<li>reliable-unreliable 可靠的 - 不可靠的</li>
<li>exploit 利用</li>
<li>in terms of 就。。。而言,从。。。观点来看</li>
<li>engage 使参与；吸引；雇佣</li>
<li>refer to 称之为</li>
<li>calve 产子</li>
<li>exploision 爆炸；突然出现</li>
<li>sophisticate 使更精确</li>
<li>threshold 下限；门槛</li>
<li>intermidiate 中距离</li>
<li>rotation 旋转</li>
<li>assimilation 同化，融合</li>
</ul>
</li>
<li><p>Semi-supervise</p>
<p>  <img src="Pattern%20recognition%20and%20machine%20learning%20e1f94fd17812467f8adc1a323302ed35/%E6%88%AA%E5%B1%8F2022-04-06_15.50.55.png" alt="截屏2022-04-06 15.50.55.png"></p>
</li>
<li><p>crowdsourcing</p>
<p>  Request tasks to unspecified large number of people</p>
<p>  (E.g. To let them annotation the object(迷惑メール))</p>
</li>
</ul>
<h3 id="SV3-Data-assimilation"><a href="#SV3-Data-assimilation" class="headerlink" title="SV3 Data assimilation"></a>SV3 Data assimilation</h3><ul>
<li>English<ul>
<li>oceangraphical 海洋学的</li>
<li>incorporate 纳入；合并</li>
<li>in contrast 相反的</li>
<li>operation 运行，实施，行动</li>
<li>meteorological 气象学的</li>
<li>intuition 直觉</li>
<li>consist of 包括</li>
<li>induce 劝说，促使</li>
<li>influx 流入 涌入</li>
<li>pot 笼子</li>
<li>emulate 模仿 仿真</li>
<li>sophiscated 需要经验的</li>
<li>stochastic 随机的</li>
<li>fomulation 构想；体系化，公式化</li>
<li>state equation 状态方程式</li>
<li>observation equation 观测方程式</li>
<li>degree 程度，阶段</li>
<li>dotted line 虚线</li>
<li>phenomenon 现象</li>
</ul>
</li>
<li>Data Assimilation(データ同化、数据同化)<ul>
<li>主に<a href="https://ja.wikipedia.org/wiki/%E5%9C%B0%E7%90%83%E7%A7%91%E5%AD%A6">地球科学</a>の分野において数値<a href="https://ja.wikipedia.org/wiki/%E6%95%B0%E7%90%86%E3%83%A2%E3%83%87%E3%83%AB">モデル</a>の再現性を高めるために行われる作業である。簡単に言えば、モデルに実際の観測値を入力してより現実に近い結果が出るようにすることを指す。</li>
</ul>
</li>
<li>GBDT<ul>
<li>GBDTとは「勾配降下法(Gradient)」と「Boosting(アンサンブル)」、「決定木(Decision Tree)」を組み合わせた手法です。</li>
</ul>
</li>
</ul>
<blockquote>
<p>In this case (for forcasting the fish catchs), we get better result in DATA ASSIMILATION but not machine learning .<br>Because we can’t deal with data that not happend in the previous data<br>But in DA,we can incorporate expert’s knowledge when make a model so it can predict very well although we only have a few of data</p>
</blockquote>
<h3 id="Summarize"><a href="#Summarize" class="headerlink" title="Summarize"></a>Summarize</h3><p><img src="Pattern%20recognition%20and%20machine%20learning%20e1f94fd17812467f8adc1a323302ed35/%E6%88%AA%E5%B1%8F2022-04-07_17.54.35.png" alt="截屏2022-04-07 17.54.35.png"></p>
<h2 id="2-Feature-embedding"><a href="#2-Feature-embedding" class="headerlink" title="2. Feature embedding"></a>2. Feature embedding</h2><ul>
<li>English<ul>
<li>dimensionality reduction 次元削減</li>
<li>coordinate 座標</li>
<li>orthonormal coordinate 正規系座標系</li>
<li>basis 基底</li>
<li>subspace 部分空間</li>
<li>projection function 射影変換</li>
<li>Principal Component Analysis 主成分分析</li>
<li>prime　プライム；上标号</li>
<li>scatter 分散，散布</li>
<li>axis 轴</li>
<li>formulate 构想，创建，表达</li>
<li>notation memo</li>
<li>constraint 限制</li>
<li>derivative 导数</li>
<li>eigenvalue 固有值</li>
<li>eigenvector 固有向量</li>
<li>correspond 相符，相当</li>
<li>consistent 一致的</li>
</ul>
</li>
</ul>
<h3 id="Dimensionality-Reduction"><a href="#Dimensionality-Reduction" class="headerlink" title="Dimensionality Reduction"></a>Dimensionality Reduction</h3><p><strong>Goal: Reduct dimensions but minimize the loss of information</strong></p>
<p><img src="Pattern%20recognition%20and%20machine%20learning%20e1f94fd17812467f8adc1a323302ed35/%E6%88%AA%E5%B1%8F2022-04-08_16.36.37.png" alt="截屏2022-04-08 16.36.37.png"></p>
<p><img src="Pattern%20recognition%20and%20machine%20learning%20e1f94fd17812467f8adc1a323302ed35/%E6%88%AA%E5%B1%8F2022-04-08_16.37.05.png" alt="截屏2022-04-08 16.37.05.png"></p>
<p>T : a projection function</p>
<p>x: data will to be reducted</p>
<p>z: reducted data</p>
<h3 id="Principal-Component-Analysis-PCA"><a href="#Principal-Component-Analysis-PCA" class="headerlink" title="Principal Component Analysis(PCA)"></a>Principal Component Analysis(PCA)</h3><ul>
<li><p>Minimum Loss of Information = Maximum Variance</p>
<p>  <img src="Pattern%20recognition%20and%20machine%20learning%20e1f94fd17812467f8adc1a323302ed35/%E6%88%AA%E5%B1%8F2022-04-08_17.00.14.png" alt="截屏2022-04-08 17.00.14.png"></p>
<p>  OA is a constant → Minimize error AA’ = Maximize variance OA’</p>
<pre><code>                              → Sum of errors over all samples would be     
</code></pre><p>  minimized.= Variance of all projected samples on subspace<br>  would be maximized.</p>
</li>
<li><p>検証</p>
<p>  <img src="Pattern%20recognition%20and%20machine%20learning%20e1f94fd17812467f8adc1a323302ed35/Untitled.png" alt="Untitled"></p>
<p>   **射影の分散の平均値を0としています</p>
</li>
<li><p>手順：</p>
<ol>
<li>sample x の分散共分散行列求める</li>
<li>固有値、固有ベクトル求める</li>
<li>固有値の絶対値大きいほど、大きい分散しているを表す。対応のベクトルは第一成分。</li>
</ol>
</li>
<li><p>評価方法</p>
<ul>
<li><p>寄与率</p>
<p>  <img src="Pattern%20recognition%20and%20machine%20learning%20e1f94fd17812467f8adc1a323302ed35/%E6%88%AA%E5%B1%8F2022-04-11_15.30.44.png" alt="截屏2022-04-11 15.30.44.png"></p>
</li>
<li><p>累積寄与率</p>
<p>  <img src="Pattern%20recognition%20and%20machine%20learning%20e1f94fd17812467f8adc1a323302ed35/%E6%88%AA%E5%B1%8F2022-04-11_15.31.50.png" alt="截屏2022-04-11 15.31.50.png"></p>
</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>study</category>
      </categories>
      <tags>
        <tag>PR</tag>
      </tags>
  </entry>
  <entry>
    <title>无约束优化</title>
    <url>/2022/05/11/Unconstrained%20minimization/</url>
    <content><![CDATA[<h2 id="1-问题定义"><a href="#1-问题定义" class="headerlink" title="1 问题定义"></a>1 问题定义</h2><script type="math/tex; mode=display">\text{minimize } f(x)</script><ul>
<li>二次可微凸函数</li>
<li>$p^*$为最优值（最优解的y值）</li>
</ul>
<h3 id="1-2-初始点"><a href="#1-2-初始点" class="headerlink" title="1.2 初始点"></a>1.2 初始点</h3><p>以下方法需要初始点$x^{(0)} \in domf$，且下水平集必须为闭集，即：</p>
<script type="math/tex; mode=display">S={x \in dom f | f(x)\le f(x^{(0)})}</script><h3 id="1-3-例子"><a href="#1-3-例子" class="headerlink" title="1.3 例子"></a>1.3 例子</h3><ul>
<li>二次优化</li>
<li>无约束几何规划</li>
<li>线性不等式的解析中心</li>
</ul>
<h2 id="2-强凸性"><a href="#2-强凸性" class="headerlink" title="2. 强凸性"></a>2. 强凸性</h2><p>假设目标函数在S上是强凸的，指$\exist m&gt;0$使得</p>
<script type="math/tex; mode=display">\nabla^2 f(x) \succeq mI</script><p>对$\forall x \in S$成立</p>
<p>并且，对于$x,y\in S$有</p>
<script type="math/tex; mode=display">f(y)=f(x)+\nabla f(x)^T(y-x)+\frac{1}{2}(y-x)^T\nabla^2f(z)(y-x)</script><p>其中z属于[x,y]的线段。根据强凸性条件，可推出</p>
<script type="math/tex; mode=display">f(y)\geq f(x)+\nabla f(x)^T(y-x)+\frac{m}{2}||y-x||^2_2</script><ul>
<li>m=0时，就是描述凸性的基本不等式</li>
</ul>
<div class="note info modern"><p>并且可以通过此式推出$f(x)和p^*$的关系</p>
</div>
<p>将右式看作关于y的二次函数，则对y求导后=0时的y为最优解，即$\hat{y}=x-(1/m)\nabla f(x)$<br>则</p>
<script type="math/tex; mode=display">f(y)\geq f(x)+\nabla f(x)^T(\hat{y}-x)+\frac{m}{2}||\hat{y}-x||^2_2</script><script type="math/tex; mode=display">=f(x)-\frac{1}{2m}||\nabla f(x)||^2_2</script><p>因为这个不等式将对任何f(y)都成立，因此对于最优值也有：</p>
<script type="math/tex; mode=display">p^*\geq f(x)-\frac{1}{2m}||\nabla f(x)||^2_2</script><h3 id="2-1-二次导的上界"><a href="#2-1-二次导的上界" class="headerlink" title="2.1 二次导的上界"></a>2.1 二次导的上界</h3><p>由上式知S所包含的所有下水平集都有界，因此对于$\nabla^2f(x)$应该也是有界的，即</p>
<script type="math/tex; mode=display">\nabla^2f(x)\preceq MI</script><p>对所有$x\in S$ 成立。<br>这个上界意味着对于所有$x,y\in S$有</p>
<script type="math/tex; mode=display">f(y)\leq f(x)+\nabla f(x)^T(y-x)+\frac{M}{2}||y-x||^2_2</script><blockquote>
<p>注意与强凸推导的式1之类似</p>
</blockquote>
<p>上式求极小后得</p>
<script type="math/tex; mode=display">p^*\leq f(x)-\frac{1}{2M}||\nabla f(x)||^2_2</script><h3 id="2-2-下水平集的条件数"><a href="#2-2-下水平集的条件数" class="headerlink" title="2.2 下水平集的条件数"></a>2.2 下水平集的条件数</h3><p>上界和下界为</p>
<script type="math/tex; mode=display">mI\preceq \nabla^2f(x)\preceq MI</script><p>因此$k=M/m$是$\nabla^2f(x)$的条件数(condition number)（即最大特征值和最小特征值的比值）</p>
<p>根据这个，可以用来决定停止条件(stopping condition)。如果我们在 ${||\nabla f(x^{(k)})||_2\leq \eta}$时终止算法，其中$\eta$是小于$(m\epsilon)^{1/2}$的充分小的数，那我们就能得到一个</p>
<script type="math/tex; mode=display">{f(x^{(k)})-p^*\leq \epsilon}</script><h2 id="3-下降方法"><a href="#3-下降方法" class="headerlink" title="3 下降方法"></a>3 下降方法</h2><p>本章描述的算法将生成一系列的优化点，其中</p>
<script type="math/tex; mode=display">x^{(k+1)}=x^{(k)}+t^{(k)}\Delta x^{(k)}</script><ul>
<li>$\Delta x^{(k)} \in R^n$为步径(step)或搜索方向(search direction)</li>
<li>$t^{(k)}\geq 0$为步进(step size)或步长(step length)</li>
<li>只要$x^{(k)}$还不是最优解$x^*$，就一定$t^{(k)}&gt; 0$</li>
</ul>
<h4 id="3-1-下降的限制条件"><a href="#3-1-下降的限制条件" class="headerlink" title="3.1 下降的限制条件"></a>3.1 下降的限制条件</h4><p>既然被称为下降方法，很容易想到</p>
<script type="math/tex; mode=display">f(x^{(k+1)})<f(x^{(k)})</script><h4 id="3-2-搜索方向条件"><a href="#3-2-搜索方向条件" class="headerlink" title="3.2 搜索方向条件"></a>3.2 搜索方向条件</h4><p>并且由凸性一阶条件可知$f(y)\geq f(x^{(k)})$，因此搜索方向必须满足</p>
<script type="math/tex; mode=display">\nabla f(x^{(k)})^T\Delta x^{(k)}<0</script><h4 id="3-3-通用下降方法-General-descent-method"><a href="#3-3-通用下降方法-General-descent-method" class="headerlink" title="3.3 通用下降方法(General descent method)"></a>3.3 通用下降方法(General descent method)</h4><ol>
<li>给定初始点$x\in dom f$</li>
<li>LOOP<ol>
<li>确定下降方向</li>
<li>直线搜索，选择步长t</li>
<li>更新x</li>
</ol>
</li>
<li>STOP 满足停止准则</li>
</ol>
<h4 id="3-4-下降方法例子"><a href="#3-4-下降方法例子" class="headerlink" title="3.4 下降方法例子"></a>3.4 下降方法例子</h4><ol>
<li>精确直线搜索（exact line search）</li>
<li>回溯直线搜索 (backtracking line search)</li>
</ol>
<h2 id="4-梯度下降法-Gradient-descent-method）"><a href="#4-梯度下降法-Gradient-descent-method）" class="headerlink" title="4 梯度下降法(Gradient descent method）"></a>4 梯度下降法(Gradient descent method）</h2><ol>
<li>给定初始点$x\in dom f$</li>
<li>LOOP<ol>
<li>$\Delta x:=-\nabla f(x)$</li>
<li>直线搜索，通过精确或回溯法确定t</li>
<li>更新x</li>
</ol>
</li>
<li>STOP 满足停止准则</li>
</ol>
<ul>
<li>停止准则一般取$||\nabla f(x)||_2\leq \eta$, $\eta$为极小的正数</li>
</ul>
<h2 id="5-收敛性分析（convergence-analysis）"><a href="#5-收敛性分析（convergence-analysis）" class="headerlink" title="5 收敛性分析（convergence analysis）"></a>5 收敛性分析（convergence analysis）</h2><blockquote>
<p>NOTE</p>
<ul>
<li>$x^+=x+t\Delta x$表示更新</li>
<li>$\Delta x=-\nabla f(x)$</li>
</ul>
</blockquote>
<p>假设f为强凸函数，并定义$\hat{f}(t)=f(x-\nabla f(x))$为关于步长t的函数（可以看做是测试当t变化时f(x)有什么影响的函数？）</p>
<p>将$y=x-\nabla f(x)$代入到“二次导的上界”的推导式1中可得</p>
<script type="math/tex; mode=display">\hat{f}(t)\leq f(x)-t||\nabla f(x)^||^2_2+\frac{Mt^2}{2}||\nabla f(x)^||^2_2</script><h3 id="5-1-精确直线搜索的分析"><a href="#5-1-精确直线搜索的分析" class="headerlink" title="5.1 精确直线搜索的分析"></a>5.1 精确直线搜索的分析</h3><h3 id="5-2-回溯直线搜索的分析"><a href="#5-2-回溯直线搜索的分析" class="headerlink" title="5.2 回溯直线搜索的分析"></a>5.2 回溯直线搜索的分析</h3><h3 id="5-3-例：-R-2-空间的二次问题"><a href="#5-3-例：-R-2-空间的二次问题" class="headerlink" title="5.3 例：$R^2$空间的二次问题"></a>5.3 例：$R^2$空间的二次问题</h3><div class="note info modern"><p>结论：</p>
</div>
<h2 id="6-最速下降法-steepest-descent-method"><a href="#6-最速下降法-steepest-descent-method" class="headerlink" title="6 最速下降法(steepest descent method)"></a>6 最速下降法(steepest descent method)</h2><h3 id="6-1-下降方向"><a href="#6-1-下降方向" class="headerlink" title="6.1 下降方向"></a>6.1 下降方向</h3><p>对$f(x+v)$在x处进行一阶泰勒展开</p>
<script type="math/tex; mode=display">f(x+v)\approx \hat{f}(x+v)=f(x)+\nabla f(x)^Tv</script><ul>
<li>其中右边$\nabla f(x)^Tv$为f在x处沿方向v的方向导数(directional derivative)</li>
<li>方向导数近似表示了f沿小步径v会发生的变化</li>
</ul>
<h3 id="6-2-规范化的最速下降方向-normalized-steepest-descent"><a href="#6-2-规范化的最速下降方向-normalized-steepest-descent" class="headerlink" title="6.2 规范化的最速下降方向(normalized steepest descent )"></a>6.2 规范化的最速下降方向(normalized steepest descent )</h3><p>为了限制v的大小，我们定义一个规范化的最速下降方向。其中||*||是$R^n$上的任意范数</p>
<script type="math/tex; mode=display">\Delta x_{nsd}=argmin\{\nabla f(x)^Tv|\|v\|=1\}</script><h3 id="6-3-最速下降法算法"><a href="#6-3-最速下降法算法" class="headerlink" title="6.3 最速下降法算法"></a>6.3 最速下降法算法</h3><ol>
<li>给定初始点$x\in dom f$</li>
<li>LOOP<ol>
<li>计算最速下降方向$\Delta x_{nsd}$</li>
<li>直线搜索，通过精确或回溯法确定t</li>
<li>更新x</li>
</ol>
</li>
<li>STOP 满足停止准则</li>
</ol>
<h3 id="6-4-不同范数下的最速下降"><a href="#6-4-不同范数下的最速下降" class="headerlink" title="6.4 不同范数下的最速下降"></a>6.4 不同范数下的最速下降</h3><h4 id="6-4-1-Eclid范数（EUCLIDEAN-NORM）"><a href="#6-4-1-Eclid范数（EUCLIDEAN-NORM）" class="headerlink" title="6.4.1 Eclid范数（EUCLIDEAN NORM）"></a>6.4.1 Eclid范数（EUCLIDEAN NORM）</h4><p>取Euclid范数时</p>
<script type="math/tex; mode=display">\Delta x_{sd}=-\nabla f(x)</script><h4 id="6-4-2-二次范数（quadratic-norm）"><a href="#6-4-2-二次范数（quadratic-norm）" class="headerlink" title="6.4.2 二次范数（quadratic norm）"></a>6.4.2 二次范数（quadratic norm）</h4><p>二次范数</p>
<script type="math/tex; mode=display">||z||_p=(z^TPz)^{1/2}=||P^{1/2}z||_2</script><p>其中$P\in S_{++}^n$.<br>规范化的最速下降方向为</p>
<script type="math/tex; mode=display">\Delta x_{sd}=-(\nabla f(x)^TP^{-1}\nabla f(x))^{-1/2}P^{-1}\nabla f(x)</script><p>并且对偶范数为$||z||_<em>=||-P^{-1}\nabla f(x)||$,因此采用$||</em>||_P$的最速下降步径为</p>
<script type="math/tex; mode=display">\Delta x_{sd}=-P^{-1}\nabla f(x)</script><blockquote>
<p>基于坐标变换</p>
</blockquote>
<h4 id="6-4-3-范数选择"><a href="#6-4-3-范数选择" class="headerlink" title="6.4.3 范数选择"></a>6.4.3 范数选择</h4>]]></content>
      <categories>
        <category>study</category>
      </categories>
      <tags>
        <tag>CGO</tag>
      </tags>
  </entry>
  <entry>
    <title>SIFT</title>
    <url>/2022/05/13/SIFT/</url>
    <content><![CDATA[<h2 id="SIFT究竟在做什么？"><a href="#SIFT究竟在做什么？" class="headerlink" title="SIFT究竟在做什么？"></a>SIFT究竟在做什么？</h2><h3 id="WHAT"><a href="#WHAT" class="headerlink" title="WHAT"></a>WHAT</h3><p>SIFT属于传统特征提取方式，与通过深度学习的反复学习提取出的特征值不同，传统特征提取方式需要通过人工计算和模拟实验找到所需要的特征点。一个好的特征量应该具有尺度不变的性质，本文就是在解释通过怎样的计算步骤能找到这样的特征量。</p>
<h3 id="WHY"><a href="#WHY" class="headerlink" title="WHY"></a>WHY</h3><p>特征量往往被用在物体识别，物体</p>
<h3 id="HOW"><a href="#HOW" class="headerlink" title="HOW"></a>HOW</h3><h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>这篇文章帮助我们从图片中提取出图像特征，能满足即使当这个图片中某一事物或场景发生了失真，视角偏移，噪点增添或是光线改变时，也能将图片间的相关点进行对应。而且他它们是易于区分的特征，即使是从庞大的特征库中也能利用它们找到对应的真正的物体或场景。</p>
<h2 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h2><p>分为以下三步</p>
<ol>
<li>尺度空间的极值提取</li>
<li>关键点定位</li>
<li>方向分配</li>
<li>关键点描述</li>
</ol>
<p>这一系列的方法称作为SIFT,即尺度不变的特征转换。</p>
<h3 id="1-尺度空间的极值提取"><a href="#1-尺度空间的极值提取" class="headerlink" title="1. 尺度空间的极值提取"></a>1. 尺度空间的极值提取</h3><h4 id="生成高斯图像、尺度空间"><a href="#生成高斯图像、尺度空间" class="headerlink" title="生成高斯图像、尺度空间"></a>生成高斯图像、尺度空间</h4><p>极值提取的计算式，将使用DoG进行计算。首先我们已经知道唯一可行的尺度空间核就是高斯核，因此我们使用高斯函数对图像进行卷积从而得到尺度空间。其次，Lindebeg在1994年提出了LoG是对于尺度不变检测的必要算子。并且，Mikolajczyk提出利用LoG的最小值和最大值之差可以求出图片的稳定特征。而DoG正好可以近似于LoG。</p>
<p>对于每个尺度空间，通过将原始图像与高斯核不断卷积，并将临近的生成图像相减形成高斯差值图像。之后，对图像进行下采样，再进行同样的工作。这样保证采样精度不变的情况下，计算量大大下降。</p>
<h4 id="局部极值提取"><a href="#局部极值提取" class="headerlink" title="局部极值提取"></a>局部极值提取</h4><p>每个点将会和坐标空间上的8个临近点，以及尺度空间上的18个点，共计26个点进行比较。只有在27个点中是最小或最大才会被定义为极值。由于我们可以进行一些前处理筛选掉大部分的点，所以极值验证的过程并不会花费很大。</p>
<p>明显的是，采样频率关系到极值的选择。但不幸的是并没有确定的采样频率能使我们一定能找到所需的极值。因此我们使用实验的方法来决定最优频率。</p>
<h5 id="尺度上的采样频率"><a href="#尺度上的采样频率" class="headerlink" title="尺度上的采样频率"></a>尺度上的采样频率</h5><p>我们测试了当改变尺度空间上的采样时，重现率和关键点检测数量的改变趋势。结果表明，当采样频率增加时，重现率有下降趋势，这有可能因为即使找到了更多的极值，但他们不够稳定；并且，随着频率增加，更多的关键点被检测出来，虽然他们有助于物体检测，但运算量也大大上升，因此我们折中选择了3这个尺度空间的采样频率。</p>
<h5 id="空间上的采样频率"><a href="#空间上的采样频率" class="headerlink" title="空间上的采样频率"></a>空间上的采样频率</h5><p>通过测试预平滑的采样频率与重现率的关系我们发现，当频率越大重现率也越大，但为了保证运行的效率，我们选择了1.6这个值。</p>
<h3 id="2-精确的关键点定位"><a href="#2-精确的关键点定位" class="headerlink" title="2. 精确的关键点定位"></a>2. 精确的关键点定位</h3><p>上个步骤中我们找到了离散空间的极值候选者，但不一定是真正的连续函数上的极值。本章通过对取样点的D(x)求导得出偏移量，以寻找真正的极值。首先，如果偏移值大于0.5则认为极值在相邻的采样点。其次，如果有极值点的D(x)是小于0.03的我们认为它是不稳定的，因此也会被舍弃。</p>
<h4 id="消除边缘响应"><a href="#消除边缘响应" class="headerlink" title="消除边缘响应"></a>消除边缘响应</h4><p>当主曲率过大时我们认为这是边缘上的点，由于边缘点并不稳定我们需要去除。通过计算，我们只要通过计算海塞矩阵的对角和行列式的比值就能求出特征值之比，这大大减少了计算量。本文将特征值的比值阈值设为10，大于10的将被去除。</p>
<h3 id="3-方向分配"><a href="#3-方向分配" class="headerlink" title="3. 方向分配"></a>3. 方向分配</h3><p>对于每个关键点，我们通过统计临近区域的点的向量和角度来确定关键点的方向。通过直方图的形式统计被分配在各个角度的临近点的数量，取最多的为关键点的方向。此外，若有其他方向的统计值高于最高值的80%，我们将其认定为第二方向。</p>
<h3 id="4-特征点描述"><a href="#4-特征点描述" class="headerlink" title="4. 特征点描述"></a>4. 特征点描述</h3><p>我们已经知道使用神经元模型，即计算出特定方向和空间次数的梯度可以得到非常稳定的特征量，可以用于视角改变和亮度改变的问题。</p>
<h4 id="特征量表现"><a href="#特征量表现" class="headerlink" title="特征量表现"></a>特征量表现</h4><p>通过计算和统计关键点周围像素的向量方向分布，对关键点进行描述。本文中我们将对16<em>16的范围的区域分成4\</em>4的格子，来对它们的8个向量方向进行统计。<br>此外，为了对光照变化具有不变性，我们还要对向量归一化。这样能减少光亮变化而产生的对梯度带来的线性变化。其次，为向量长度设置阈值，减小值较大的向量的重要度，以减少对非线性光照变化的敏感度。</p>
<h4 id="对仿射变换的敏感性"><a href="#对仿射变换的敏感性" class="headerlink" title="对仿射变换的敏感性"></a>对仿射变换的敏感性</h4><p>根据实验，当仿射度上升时匹配度大幅度下降。但实际上在3D图像上的可旋转范围较小，仿射不变性并不是那么重要。而如果在平面图片上时，我们可以使用xx的方法生成额外的SIFT特征量，使得最终生成标准特征库三倍量的特征。</p>
<h4 id="对大数据集的对比"><a href="#对大数据集的对比" class="headerlink" title="对大数据集的对比"></a>对大数据集的对比</h4><p>更多是因为初始特征的位置和方向的分配问题而不是特征的可区分度造成的</p>
<h2 id="对物体识别的应用"><a href="#对物体识别的应用" class="headerlink" title="对物体识别的应用"></a>对物体识别的应用</h2><h3 id="1-关键点匹配"><a href="#1-关键点匹配" class="headerlink" title="1. 关键点匹配"></a>1. 关键点匹配</h3><p>我们对每个关键点与数据库中的特征进行匹配，得到欧几里得距离最近的候选项。但是实际上许多特征来自于杂乱的背景或对于这个物体的识别并没有帮助。因此我们通过一个高效的手法剔除掉这些无用的特征。这个方法就是对比与最近的正确图像的距离，和最近的错误图像的距离之比。当这个比值大于0.8时（即错误图像的距离高于正确图像的距离的80%时），我们就淘汰这个特征。</p>
<h3 id="有效的最近邻法"><a href="#有效的最近邻法" class="headerlink" title="有效的最近邻法"></a>有效的最近邻法</h3><p>我们使用BBF算法来搜索最近的点。这个算法对于我们的特征值最有效，考虑原因可能是上章提到我们只需要探索距离比值小于0.8的特征点。</p>
<h3 id="霍夫变换聚类"><a href="#霍夫变换聚类" class="headerlink" title="霍夫变换聚类"></a>霍夫变换聚类</h3><p>为了提高对小物体和被遮挡物体的识别问题，我们希望即使少类的特征也能识别出物体。而通过霍夫变换将特征值聚类的方法能提升这一可能性。</p>
<p>[1] <a href="https://blog.csdn.net/lavender19/article/details/120396145">https://blog.csdn.net/lavender19/article/details/120396145</a><br>[2]<a href="https://blog.csdn.net/shiyongraow/article/details/78296710">https://blog.csdn.net/shiyongraow/article/details/78296710</a><br>[3]<a href="https://www.cnblogs.com/shine-lee/p/10950963.html">https://www.cnblogs.com/shine-lee/p/10950963.html</a> 仿射变换</p>
]]></content>
      <categories>
        <category>study</category>
      </categories>
      <tags>
        <tag>CV</tag>
      </tags>
  </entry>
  <entry>
    <title>detection</title>
    <url>/2022/05/10/corner%20detection/</url>
    <content><![CDATA[]]></content>
      <categories>
        <category>study</category>
      </categories>
      <tags>
        <tag>CV</tag>
      </tags>
  </entry>
  <entry>
    <title>edge detection</title>
    <url>/2022/05/09/edge%20detection/</url>
    <content><![CDATA[<h1 id="1-Feature-detection"><a href="#1-Feature-detection" class="headerlink" title="1 Feature detection"></a>1 Feature detection</h1><blockquote>
<ul>
<li>Containing vast information</li>
</ul>
</blockquote>
<p>SO it’s important to <mark class="hl-label red">determine</mark> </p>
<ol>
<li><p>WHERE</p>
<ul>
<li><strong>concentrate on a part</strong> and <strong>ignore others</strong></li>
<li>e.g. Object recognition: Ignore background</li>
</ul>
</li>
<li><p>WHAT</p>
<ul>
<li>Feature can be located<ul>
<li>edge</li>
<li>feature points</li>
</ul>
</li>
</ul>
</li>
</ol>
<h1 id="2-Edge-detection"><a href="#2-Edge-detection" class="headerlink" title="2 Edge detection"></a>2 Edge detection</h1><h2 id="2-1-Feature"><a href="#2-1-Feature" class="headerlink" title="2.1 Feature"></a>2.1 Feature</h2><ol>
<li>Brightness (value) changes <strong>rapidly</strong></li>
<li>Differentiation (近傍ピクセルとの微分処理 ) </li>
<li>Important feature for object recognition </li>
<li>Weak to noise(Because it is differentiation)</li>
</ol>
<h2 id="2-2-Kinds"><a href="#2-2-Kinds" class="headerlink" title="2.2 Kinds"></a>2.2 Kinds</h2><p><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h22h9p2btmj211z0n2abr.jpg" alt=""></p>
<h2 id="2-3-Differentiation"><a href="#2-3-Differentiation" class="headerlink" title="2.3 Differentiation"></a>2.3 Differentiation</h2><ul>
<li><p>Grandient</p>
<script type="math/tex; mode=display">\nabla I=(\frac{\partial I}{\partial x}, \frac{\partial I}{\partial y})</script><ul>
<li>Represents the<strong> direction and the speed</strong> of the <strong>change in brightness </strong></li>
</ul>
</li>
<li><p>Laplacian</p>
<script type="math/tex; mode=display">\nabla^2 I=(\frac{\partial^2 I}{\partial x^2}, \frac{\partial^2 I}{\partial y^2})</script></li>
</ul>
<div class="note info modern"><p>边缘就是明暗剧烈变化的地方，所以我们可以通过一次微分的极值或二次微分的变曲点确定edge</p>
</div>
<p><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h231usx1ugj20sl0gd764.jpg" alt=""></p>
<h1 id="3-edge-operator"><a href="#3-edge-operator" class="headerlink" title="3 edge operator"></a>3 edge operator</h1><blockquote>
<p>为了计算微分，我们通过edge operator——即一种filter来实现</p>
</blockquote>
<h2 id="3-1-一次微分"><a href="#3-1-一次微分" class="headerlink" title="3.1 一次微分"></a>3.1 一次微分</h2><p>对于一个形同$[[I_{i,j+1}, I_{i+1,j+1}],[I_{i,j}, I_{i+1,j}]]$的2*2 window内的像素，我们可以将微分转换为</p>
<script type="math/tex; mode=display">\frac{\partial I}{\partial x} \approx \frac{1}{2\varepsilon}((I_{i+1,j+1}-I_{i,j+1})+(I_{i+1,j}-I_{i,j}))</script><script type="math/tex; mode=display">\frac{\partial I}{\partial y} \approx \frac{1}{2\varepsilon}((I_{i,j+1}-I_{i,j})+(I_{i+1,j+1}-I_{i+1,j}))</script><p>表现为filter即为</p>
<p><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h231ypgyluj20vp0audgc.jpg" alt=""></p>
<p>分别求出两个方向的edge后合并才能生成总的edge图</p>
<ul>
<li>Location more precise</li>
<li>Weak to noise </li>
<li>Low detection power<br><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h231uu19ctj20ut0gu40l.jpg" alt=""><script type="math/tex; mode=display">对噪声的优化很弱的后果...处处都是边缘！</script></li>
</ul>
<h2 id="3-2-二次微分"><a href="#3-2-二次微分" class="headerlink" title="3.2 二次微分"></a>3.2 二次微分</h2><p><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h231utawi2j20cg0aeq3b.jpg" alt=""></p>
<script type="math/tex; mode=display">\frac{\partial^2 I}{\partial x^2} \approx \frac{1}{\varepsilon^2}(I_{i-1,j}-2I_{i,j}+I_{i+1,j})</script><script type="math/tex; mode=display">\frac{\partial^2 I}{\partial y^2} \approx \frac{1}{\varepsilon^2}(I_{i,j-1}-2I_{i,j}+I_{i,j+1})</script><p><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h231utl5ycj210q08xq3v.jpg" alt=""></p>
<h2 id="3-3-算法"><a href="#3-3-算法" class="headerlink" title="3.3 算法"></a>3.3 算法</h2><ul>
<li>Roberts</li>
<li>Prewitt<ul>
<li>先ほどのカーネルではノイズの影響が非常に強く出てしまうので、平滑化処理を加えた形</li>
</ul>
</li>
<li><p>Sobel</p>
<ul>
<li>Location imprecise </li>
<li>Robust to noise </li>
<li>High detection power </li>
</ul>
</li>
<li><p>LoG<br><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h231uui5vej20xn0pbjuq.jpg" alt=""></p>
<ul>
<li>用于平滑化</li>
<li>近似于DOG（倒不如说有时候用DOG会更方便所以可以近似）</li>
</ul>
</li>
<li>Canny<ul>
<li>通过将一系列的检出算法合并的强力检出工具<ol>
<li>Blur image I with 2D Gaussian</li>
<li>Find the edge‐normal direction at each pixel:</li>
<li>Calculate the strength of the edge</li>
<li>Find the maximal strength in the edge‐normal direction as the zero‐crossing in that direction (this step is called non‐maximum suppression)</li>
</ol>
</li>
<li>改变参数$\sigma$可以提取各种各样不同的特征 </li>
</ul>
</li>
</ul>
<h1 id="4-Corner-detection"><a href="#4-Corner-detection" class="headerlink" title="4. Corner detection"></a>4. Corner detection</h1><blockquote>
<p>除了通过微分求出练成线的轮廓线，我们还可以通过求物体“角点”确认物体的位置</p>
</blockquote>
<h2 id="4-1-Susan"><a href="#4-1-Susan" class="headerlink" title="4.1 Susan"></a>4.1 Susan</h2><ol>
<li>window作为一个圆形对图片遍历，圈内与圆心相同亮度的部分称为USAN</li>
<li>若USAN的面积小于某个阈值即认为这个点是角点（就是在圆内占比极低）<blockquote>
<p>想象一个比例为1:3的饼状统计图…那1/4是不是就是个正方形的角？</p>
</blockquote>
</li>
<li>USAN面积排行<ol>
<li>圆内全部为相同亮度（即在一个物体内部时）面积最大</li>
<li>圆内只有一半左右为相同亮度（即边缘）面积次大</li>
<li>圆内只有小部分为相同亮度时（即角）面积最小<br><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h232kivengj20iw0ck75h.jpg" alt=""></li>
</ol>
</li>
</ol>
<h2 id="4-2-harris"><a href="#4-2-harris" class="headerlink" title="4.2 harris"></a>4.2 harris</h2><p>Detect a point where the sum of square changes<br>of the image is largest when shifted slightly</p>
<ul>
<li>Points easily distinguishable from nearby points</li>
</ul>
]]></content>
      <categories>
        <category>study</category>
      </categories>
      <tags>
        <tag>CV</tag>
      </tags>
  </entry>
  <entry>
    <title>凸优化问题</title>
    <url>/2022/05/06/%E5%87%B8%E4%BC%98%E5%8C%96%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<script type="math/tex; mode=display">\text{minimize }f_0(x)</script><script type="math/tex; mode=display">\text{subject to } f_i(x)\le 0, i=1...m</script><script type="math/tex; mode=display">h(x)=0, i=1...p</script><ul>
<li>目标函数(objective f)必须为凸(convex)</li>
<li>不等式(inequality constraint f)约束函数必须为凸</li>
<li>等式约束函数必须为仿射(affine)</li>
<li>定义域是m个凸的下水平集($f_i(x)$)和p个超平面($h(x)$)的交集</li>
<li>我们其实是在一个凸集上极小化一个凸的目标函数</li>
<li>局部最优解自动成为全局最优解</li>
</ul>
<h2 id="最优值与最优解-optimal-value-and-optimal-point"><a href="#最优值与最优解-optimal-value-and-optimal-point" class="headerlink" title="最优值与最优解 optimal value and optimal point"></a>最优值与最优解 optimal value and optimal point</h2><div class="note warning modern"><p>最优值为最优解对应的y值</p>
</div>
<p><strong>最优值</strong>定义为</p>
<script type="math/tex; mode=display">p^*=inf\{f_0(x)|满足约束条件\}</script><ul>
<li>当没有可行点（没有点满足约束条件）时，p为不可行（infeasible）且等于$\infty$</li>
<li>如果$p^*=-\infty$，则称这个问题无下界（unbounded below）</li>
</ul>
<p>当$x^{*}$可行并且$f_0(x^*)=p^{*}$时称之为<strong>最优解</strong></p>
]]></content>
      <categories>
        <category>study</category>
      </categories>
      <tags>
        <tag>optimization</tag>
      </tags>
  </entry>
  <entry>
    <title>凸集合与凸函数</title>
    <url>/2022/05/06/%E5%87%B8%E9%9B%86%E5%90%88%E4%B8%8E%E5%87%B8%E5%87%BD%E6%95%B0/</url>
    <content><![CDATA[<h2 id="1-convex-sets"><a href="#1-convex-sets" class="headerlink" title="1. convex sets"></a>1. convex sets</h2><h3 id="1-1-Line-segmentation-直线分割"><a href="#1-1-Line-segmentation-直线分割" class="headerlink" title="1.1 Line segmentation 直线分割"></a>1.1 Line segmentation 直线分割</h3><script type="math/tex; mode=display">y=\theta x_1+(1-\theta)x_2</script><script type="math/tex; mode=display">y=x_2+\theta(x_1-x_2)</script><blockquote>
<p>$\theta$=1时$y=x_1$,=0时反之，所以称为<strong>直线分割 </strong></p>
<p>根据式2也可以看做是以x_2为基准。向x_1-x_2延伸的一条线<br><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h1ykewxdwij208m048q2r.jpg" alt=""></p>
</blockquote>
<h3 id="1-2-affine-sets"><a href="#1-2-affine-sets" class="headerlink" title="1.2 affine sets"></a>1.2 affine sets</h3><p>仿射集C上的任意两点连成的直线属于C<br>即</p>
<script type="math/tex; mode=display">{\theta x_{1}+(1-\theta) x_{2} \in C, \quad \forall x_{1}, x_{2} \in C, \text { and } \theta \in \mathbb{R}}</script><p>扩展到多点上为</p>
<script type="math/tex; mode=display">x_1, x_2 ... x_k \in C</script><script type="math/tex; mode=display">\bf{AND} {\theta}_1+{\theta}_2+...+{\theta}_k=1</script><script type="math/tex; mode=display">\bf{THEN} \theta x_{1}+...+\theta_k x_{k} \in C</script><p>其中，对于属于C的子空间是<br>$V=C-x_0=\{x-x_0|x\in C\}$</p>
<blockquote>
<p>意味着标量乘积之和是闭合的</p>
</blockquote>
<p>子空间维数=仿射集维数</p>
<h3 id="1-3-affine-hull-仿射包"><a href="#1-3-affine-hull-仿射包" class="headerlink" title="1.3 affine hull 仿射包"></a>1.3 affine hull 仿射包</h3><p>aff$C=\{\theta x_{1}+…+\theta_k x_{k}|x_{1}, x_{2}…x_k\in C, \theta_1+\theta_2+…+\theta_k=1\}$</p>
<ol>
<li>C中的所有点的仿射组合组成的集合</li>
<li>仿射集维数=仿射集子空间的维数</li>
<li>是包含C的最小仿射集合</li>
</ol>
<h3 id="1-4-相对内部-relative-interior"><a href="#1-4-相对内部-relative-interior" class="headerlink" title="1.4 相对内部 relative interior"></a>1.4 相对内部 relative interior</h3><p>如果集合C的仿射维数小于n,那么aff$C\ne R ^n$<br>相对内部relint C定义为<br>$\text { relint } C =\{x \in C \mid B(x, r) \cap \operatorname{aff} C \subseteq C \text { for some } r&gt;0\}$<br>其中$B(x,y)=\{y| |y-x|\le r\}$(任意范数均可)</p>
<blockquote>
<p>（呃呃呃开始不说人话了是吧）</p>
</blockquote>
<h3 id="1-5-convex-sets-凸集"><a href="#1-5-convex-sets-凸集" class="headerlink" title="1.5 convex sets 凸集"></a>1.5 convex sets 凸集</h3><p>任意两点的线段都在C中<br>$\theta x_{1}+(1-\theta) x_{2} \in C$<br><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h1ym9ddkmrj21610aata5.jpg" alt=""><br>所有点的凸组合为凸包（convex hull）<br>conv$C=\{\theta x_{1}+…+\theta_k x_{k}|x_{1}, x_{2}…x_k\in C, \theta_1+\theta_2+…+\theta_k=1, \theta_i\ge 0\}$<br>凸包是包含C的最小凸集<br><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h1ym9epnp9j216e0b3jsg.jpg" alt=""></p>
<h2 id="2-cone-锥"><a href="#2-cone-锥" class="headerlink" title="2. cone 锥"></a>2. cone 锥</h2><p>对与任何x属于C以及$\theta$大于等于0，都有<br>$\theta x\in C$</p>
<h3 id="2-1-凸锥"><a href="#2-1-凸锥" class="headerlink" title="2.1 凸锥"></a>2.1 凸锥</h3><p>锥且凸，即<br>$\theta_1 x_1 + \theta_2 x_2\in C$<br><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h1yme7l34kj21650iddhe.jpg" alt=""></p>
<h3 id="2-2-锥包"><a href="#2-2-锥包" class="headerlink" title="2.2 锥包"></a>2.2 锥包</h3><p>所有锥组合形成的集合</p>
<h2 id="3-重要例子"><a href="#3-重要例子" class="headerlink" title="3. 重要例子"></a>3. 重要例子</h2><h3 id="3-1-一些概念"><a href="#3-1-一些概念" class="headerlink" title="3.1 一些概念"></a>3.1 一些概念</h3><ol>
<li>空集、任意一个点（即单点集）、全空间R”都是Rn的仿射（自然也是凸的)子集。</li>
<li>任意直线是仿射的。如果直线通过零点，则是子空间，因此，也是凸锥。</li>
<li>一条线段是凸的，但不是仿射的（除非退化为一个点）。</li>
<li>一条射线，即具有形式$\{x_0+\theta v|\theta≥0\}$，v≠0的集合，是凸的，但不是仿射的。如果射线的基点$x_0$是0，则它是凸锥。</li>
<li>任意子空间是仿射的、凸锥（自然是凸的）。</li>
</ol>
<h3 id="3-2-超平面"><a href="#3-2-超平面" class="headerlink" title="3.2 超平面"></a>3.2 超平面</h3><p>$\{x|a^Tx=b\}$</p>
<ul>
<li>$a\in R^n且不为0, b\in R$</li>
<li>超平面是关于x的线性方程的解空间（因此是仿射集合）</li>
</ul>
<h3 id="3-3-半空间"><a href="#3-3-半空间" class="headerlink" title="3.3 半空间"></a>3.3 半空间</h3><p>$\{x|a^Tx\le b\}$</p>
<ul>
<li>线性不等式的解空间</li>
<li>凸但不仿射</li>
<li>由超平面切割而成2个半空间</li>
</ul>
<h3 id="3-4-Euclid球"><a href="#3-4-Euclid球" class="headerlink" title="3.4 Euclid球"></a>3.4 Euclid球</h3><p>$\begin{aligned}<br>B\left(x_{c}, r\right) &amp;=\left\{x \mid\left|x-x_{c}\right|_{2} \leq r\right\} \\<br>&amp;=\left\{x \mid\left(x-x_{c}\right)^{\top}\left(x-x_{c}\right) \leq r^{2}\right\}<br>\end{aligned}$</p>
<ul>
<li>$x_c$为球心</li>
<li>r是半径</li>
</ul>
<h3 id="3-5-多面体"><a href="#3-5-多面体" class="headerlink" title="3.5 多面体"></a>3.5 多面体</h3><p>$\begin{array}{r}<br>\mathcal{P}=\left\{x \mid a_{j}^{\top} x-b_{j} \leq 0, j=1, \ldots, m\right. \\<br>\left.c_{j}^{\top} x-d_{j}=0, j=1, \ldots, p\right\}<br>\end{array}$</p>
<ul>
<li>有限个线性等式和不等式的集合（即有限个超平面和半空间的交集）</li>
<li>凸集</li>
</ul>
<h2 id="4-凸集间的保凸运算"><a href="#4-凸集间的保凸运算" class="headerlink" title="4. 凸集间的保凸运算"></a>4. 凸集间的保凸运算</h2><p>凸集之间的运算生成新的凸集</p>
<h3 id="4-1-交集"><a href="#4-1-交集" class="headerlink" title="4.1 交集"></a>4.1 交集</h3><p>$S=S1 \cap S2 $也为凸</p>
<h3 id="4-2-仿射函数"><a href="#4-2-仿射函数" class="headerlink" title="4.2 仿射函数"></a>4.2 仿射函数</h3><p>形同$f(x)=Ax+b$，对于任意点s属于凸集S，$f(s)$为凸<br>同样若有f(s)属于凸集S，则原象$f^{-1}(s)$也为凸</p>
<h3 id="4-3-透视函数"><a href="#4-3-透视函数" class="headerlink" title="4.3 透视函数"></a>4.3 透视函数</h3><p>对于$P(z,t)=z/t$（定义域为dom $P=R^n \times R_{++}$ ）</p>
<blockquote>
<p>$R_{++}为正实数$</p>
</blockquote>
<p>则对任意x属于凸C，P(x)也为凸</p>
<h2 id="5-凸函数"><a href="#5-凸函数" class="headerlink" title="5. 凸函数"></a>5. 凸函数</h2><p>$f:R^n \rightarrow R$, 若dom f为凸集，且x,y属于dom f,且$\theta$在0，1之间，则</p>
<script type="math/tex; mode=display">f(\theta x+(1-\theta) y) \leq \theta f(x)+(1-\theta) f(y)</script><ul>
<li>严格凸函数：无等号</li>
<li>凹函数：当-f是凸</li>
</ul>
<p>最大值函数就是一个凸函数：<br><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h1yqclyw6ij20r207uq3i.jpg" alt=""></p>
<h3 id="5-1-扩展值延伸-Extended-value-extensions"><a href="#5-1-扩展值延伸-Extended-value-extensions" class="headerlink" title="5.1 扩展值延伸 Extended-value extensions"></a>5.1 扩展值延伸 Extended-value extensions</h3><p>定义：当x不在dom f时，我们认为$f(x)=\infty$</p>
<h3 id="5-2-一阶条件"><a href="#5-2-一阶条件" class="headerlink" title="5.2 一阶条件"></a>5.2 一阶条件</h3><ol>
<li>dom f是凸集</li>
<li>$f(y)\ge f(x)+ \bigtriangledown f(x)^T(y-x) $</li>
</ol>
<ul>
<li>右式为f在点x附近的泰勒近似</li>
</ul>
<h3 id="5-3-二阶条件"><a href="#5-3-二阶条件" class="headerlink" title="5.3 二阶条件"></a>5.3 二阶条件</h3><p>$f(x)$的hessian矩阵为半正定，即可认为</p>
<script type="math/tex; mode=display">\bigtriangledown^2f(x) \succeq 0</script><blockquote>
<p>$\succeq$指的是矩阵中的不等式</p>
</blockquote>
<ul>
<li>对于在R上的f，我们简单的认为就是二阶导大于等于0</li>
</ul>
<h3 id="5-4-凸函数间的保凸运算"><a href="#5-4-凸函数间的保凸运算" class="headerlink" title="5.4 凸函数间的保凸运算"></a>5.4 凸函数间的保凸运算</h3><ul>
<li><p>非负加权求和</p>
<script type="math/tex; mode=display">f=w_1f_1+w_2f_2+...+w_kf_k(w非负，f凸函数)</script></li>
<li><p>复合仿射映射</p>
<script type="math/tex; mode=display">g(x)=f(Ax+b)</script><p>f凸时，g凸</p>
</li>
</ul>
]]></content>
      <categories>
        <category>study</category>
      </categories>
      <tags>
        <tag>optimization</tag>
      </tags>
  </entry>
  <entry>
    <title>无约束最优化</title>
    <url>/2022/05/04/%E6%97%A0%E7%BA%A6%E6%9D%9F%E6%9C%80%E4%BC%98%E5%8C%96/</url>
    <content><![CDATA[<h2 id="1-Minizer"><a href="#1-Minizer" class="headerlink" title="1. Minizer"></a>1. Minizer</h2><ol>
<li>全局最小值 Global Minizer</li>
<li>局部最小值 Local Minizer<ul>
<li>weak </li>
<li>strict</li>
<li>孤立的局部最小值isolated local minimizer <div class="note success modern"><p>对于凸函数，局部最小值立即成为全局最小值</p>
</div>
</li>
</ul>
</li>
</ol>
<h2 id="2-局部最小值条件"><a href="#2-局部最小值条件" class="headerlink" title="2. 局部最小值条件"></a>2. 局部最小值条件</h2><ol>
<li>一阶必要条件（FIRST-ORDER NECESSARY CONDITIONS）<ol>
<li>函数$f(x)$在点$x^*$可微</li>
<li>梯度${\nabla f(x^*)=0}$</li>
</ol>
</li>
<li>二阶必要条件<ol>
<li>满足一阶</li>
<li>hesse矩阵${\nabla^2 f(x^*)}$半正定   </li>
</ol>
</li>
</ol>
<div class="tabs" id="1"><ul class="nav-tabs"><li class="tab active"><button type="button" data-href="#1-1">海塞矩阵</button></li><li class="tab"><button type="button" data-href="#1-2">半正定值</button></li><li class="tab"><button type="button" data-href="#1-3">海塞矩阵的半正定值</button></li></ul><div class="tab-contents"><div class="tab-item-content active" id="1-1"><p><img src="https://ds055uzetaobb.cloudfront.net/brioche/uploads/gVN1lN1A28-hessian.png?width=1200" alt=""></p><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="1-2"><p>半正定值：</p>
<ol>
<li>对于所有x不等于0，都有 ${x^TAx≥0}$</li>
<li>且对某个x不等于0,有 ${x^TAx&gt;0}$</li>
</ol><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="1-3"><p>因为hesse矩阵是对称矩阵所以有以下性质：（仅限于对称矩阵！！）<br>半正定：所有特征值都大于等于0<br>正定：所有特征值都大于0<br>负定：所有特征值都小于0</p><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div></div></div>
<mark class="hl-label red">现在虽然知道了确认某点是否为最小值的算法，但是对于如何找到这个点我们还无从得知（总不能把所有点都算一遍吧）</mark> 
<h2 id="3-直线探索策略-line-search-strategy"><a href="#3-直线探索策略-line-search-strategy" class="headerlink" title="3. 直线探索策略 line search strategy"></a>3. 直线探索策略 line search strategy</h2><ol>
<li>Line Serch<br> 设在某点$x_k$，寻找方向$p_k$和步长$\alpha$使得min$f(x_k+\alpha p_k)$<br> <strong>需求值：方向和步长</strong></li>
<li>Trust Region<br> 对于点x_k上的近似函数求最小值：min$m_k(x_k+p_k)$。同时，近似函数是有限的，所以可信赖区间需要被确定。<br> <strong>需求值：近似函数和可信赖区间p</strong></li>
</ol>
]]></content>
      <categories>
        <category>study</category>
      </categories>
      <tags>
        <tag>optimization</tag>
      </tags>
  </entry>
  <entry>
    <title>闲谈-关于美术馆拍摄的变形问题</title>
    <url>/2022/05/05/%E9%97%B2%E8%B0%88-%E5%85%B3%E4%BA%8E%E7%BE%8E%E6%9C%AF%E9%A6%86%E6%8B%8D%E6%91%84%E7%9A%84%E5%8F%98%E5%BD%A2%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<p>前几天去艺术馆拍了不少喜欢的画作，本想回来美美做墙纸之类的，结果….<br><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h1xc5rlm0hj213y0u0afo.jpg" alt="除去我摄影水平不够导致的没有完美对齐的问题，和红框相比能明显看出来似乎加了鱼眼效果般突出来了点"></p>
<p><em>除去我摄影水平不够导致的没有完美对齐的问题，和红框相比能明显看出来似乎加了鱼眼效果般突出来了点</em></p>
<h2 id="镜头变形"><a href="#镜头变形" class="headerlink" title="镜头变形"></a>镜头变形</h2><p><img src="https://i.guancha.cn/bbs/2020/06/21/20200621224008407.png?imageView2/2/w/500/format/png" alt="枕形变形与鼓形变形"></p>
<blockquote>
<p>“<em>对于一般的风景画，没有多少直线，对枕形变形不太敏感；但要是以建筑为主体，或者是有较多靠近画框边缘的直线的抽象画，枕形变形就会比较扎眼。如果要把画框拍出来，平直线条紧贴着画面边缘，枕形变形特别容易显出来，佳能红圈20-70/2.8都压不住，慢说任何小数码相机了。这是拍摄绘画的“不利条件”。</em>“</p>
</blockquote>
<h2 id="球差（球面収差）"><a href="#球差（球面収差）" class="headerlink" title="球差（球面収差）"></a>球差（球面収差）</h2><p><img src="http://www.kansmemo.com/archives/001/201009/4c99aa26d1e4d.png" alt=""><br>透过镜头外侧的光和透镜片中心(近轴)附近的光,因为焦点位置不同而产生变形。原理上来说，只要镜头为球面镜头这一现象就不可避免。<br>相反,球面收差可以通过使用适当设计——非球面镜头来消除。所以,最近的镜头中非球面镜头开始被普遍使用。<br><img src="http://www.kansmemo.com/archives/001/201009/4c99aa29663c5.png" alt=""></p>
<h2 id="题外话"><a href="#题外话" class="headerlink" title="题外话"></a>题外话</h2><p>物理学的稀巴烂所以基本还停留在初中学的“凸透镜光线汇聚成一点”，所以其实理解这个费了好大的功夫。一些关于<strong>为什么与教科书不同，凸透镜的焦点并不能完美汇聚于一点</strong>的补充如下：</p>
<blockquote>
<p>聚集到一点，需要几个因素<br>1、理想平行光<br>2、理想凸透镜<br>3、理想单一频率<br>4、理想粒子特性(实际上光具有波粒两相性)</p>
</blockquote>
<p>[1]<a href="https://www.zhihu.com/question/272102579/answer/1297496356">https://www.zhihu.com/question/272102579/answer/1297496356</a><br>[2]<a href="http://www.kansmemo.com/photo/camera/principles/entry-191.html">http://www.kansmemo.com/photo/camera/principles/entry-191.html</a></p>
]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>other</tag>
      </tags>
  </entry>
  <entry>
    <title>最小二乘问题</title>
    <url>/2022/05/05/%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<h2 id="最小二乘（LEAST-SQUARES）问题定义"><a href="#最小二乘（LEAST-SQUARES）问题定义" class="headerlink" title="最小二乘（LEAST-SQUARES）问题定义"></a>最小二乘（LEAST-SQUARES）问题定义</h2><p>${f_0(x)=||Ax-b||^2_2<br>        =\sum_{i=1}^k({a_i}^Tx-b_i)^2}$</p>
<blockquote>
<p>2-范数<br>${||x||_2=(x,x)^{1/2}=\sqrt{\sum_{i=1}^n x_i^2}}$</p>
</blockquote>
<h2 id="最小二乘法"><a href="#最小二乘法" class="headerlink" title="最小二乘法"></a>最小二乘法</h2><p>上面的式子可被简化为：<br>${(A^TA)x = A^Tb}$     →    ${x = (A^TA)^{-1}A^Tb}$<br>代入原式并求hesse矩阵的话<br>${\nabla^2 ||Ax-b||^2_2=2A^TA}$<br>→ 变成了确认 ${2A^TA}$的正定值与否的问题</p>
<h2 id="补充：最小二乘"><a href="#补充：最小二乘" class="headerlink" title="补充：最小二乘"></a>补充：最小二乘</h2><ul>
<li>如下二维平面图中有很多个点，假设我们想用一条直线来拟合数据，即期望能找到一条直线能最好地穿过这些数据点。</li>
<li>一个点就可以构造一个方程，而未知数显然只有两个（直线的斜率和截距），因此这就是一个超定系统，我们是没有办法找到一条完美的直线，使得上述的点都在直线上。因此，我们只能期望找到一条最好的“适配（best fitting line）”直线来拟合这些数据</li>
<li>有x作为自变量，y表示x对应的真实值，$y^hat$表示由拟合直线对应的预测值</li>
<li>找一条直线能使得所有点离这个直线的距离平均值最小的这种近似的结果就是回归分析的目标。</li>
<li>最小二乘法主要包含了两大类方法，一种是线性最小二乘法（Linear Least Squares），一种是非线性最小二乘法（Nonlinear Least Squares）。</li>
</ul>
]]></content>
      <categories>
        <category>study</category>
      </categories>
      <tags>
        <tag>optimization</tag>
      </tags>
  </entry>
</search>
