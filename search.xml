<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Colorization using Optimization</title>
    <url>/2022/05/06/Colorization%20using%20Optimization/</url>
    <content><![CDATA[<p><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h205yxz28gj216j0dt776.jpg" alt=""></p>
<h2 id="论文概述"><a href="#论文概述" class="headerlink" title="论文概述"></a>论文概述</h2><blockquote>
<p>在本文中，我们提出了一种简单的着色方法:基于一个简单前提：时空中具有相似强度(intensity:Y)的<strong>相邻像素应该具有相似的颜色</strong>。 我们使用次成本函数形式化这个前提，并获得一个可以使用标准技术有效解决的优化问题。</p>
</blockquote>
<h3 id="目标函数"><a href="#目标函数" class="headerlink" title="目标函数"></a>目标函数</h3><p>Y可以通过gray图像作为已知信息，因此我们需要通过临近像素的推测U和V<br>MINIMIZE</p>
<script type="math/tex; mode=display">J(U) = \sum_r \left( U(r) - \sum_{s \in N(r)} w_{rs} U(s) \right)^2</script><script type="math/tex; mode=display">J(V) = \sum_r \left( V(r) - \sum_{s \in N(r)} w_{rs} V(s) \right)^2</script><ul>
<li>r: 目标像素 N(r):临近像素</li>
<li>$w_{rs}$的条件<ul>
<li>两像素间Y越相似，w越大；两像素间Y差值越大，w越小</li>
<li>和为1</li>
</ul>
</li>
</ul>
<h3 id="约束条件"><a href="#约束条件" class="headerlink" title="约束条件"></a>约束条件</h3><p>相邻像素具有相似Y时应该具有相似的U和V</p>
<h3 id="权重函数"><a href="#权重函数" class="headerlink" title="权重函数"></a>权重函数</h3><script type="math/tex; mode=display">w_{rs} \propto \exp \left( \frac{-\left(Y(r)-Y(s)\right)^2}{2 \sigma_r^2} \right)</script><ul>
<li>$\sigma_r^2$为包含r的临近像素的variance</li>
</ul>
<h2 id="实现思路"><a href="#实现思路" class="headerlink" title="实现思路"></a>实现思路</h2><ol>
<li>二乘问题的目的函数转换为解线性方程组Ax=b的问题<ul>
<li>如果按照稠密矩阵构造A就需要使用$(A^TA)^{-1}A^Tb$计算，将会十分庞大；如果用稀疏矩阵则会大大减少计算量<blockquote>
<p>呃呃搞明白以后思路就是如此简单。。。。</p>
</blockquote>
</li>
</ul>
</li>
</ol>
<h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><h3 id="import库"><a href="#import库" class="headerlink" title="import库"></a>import库</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 依赖库 </span></span><br><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> color</span><br><span class="line"><span class="keyword">from</span> scipy.sparse <span class="keyword">import</span> csr_matrix</span><br><span class="line"><span class="keyword">from</span> scipy.sparse.linalg <span class="keyword">import</span> spsolve</span><br></pre></td></tr></table></figure>
<h3 id="图像预处理"><a href="#图像预处理" class="headerlink" title="图像预处理"></a>图像预处理</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Load the images</span></span><br><span class="line"><span class="comment"># 打开图片转换为RGB再转换为YUV</span></span><br><span class="line">img_in   = color.rgb2yuv( np.array( Image.<span class="built_in">open</span>( <span class="string">&#x27;baby.png&#x27;</span> ).convert(<span class="string">&quot;RGB&quot;</span>), dtype=<span class="built_in">float</span> ) / <span class="number">255</span> )</span><br><span class="line">img_edit = color.rgb2yuv( np.array( Image.<span class="built_in">open</span>( <span class="string">&#x27;baby_marked.png&#x27;</span> ).convert(<span class="string">&quot;RGB&quot;</span>), dtype=<span class="built_in">float</span> ) / <span class="number">255</span> )</span><br><span class="line">img_hint = np.zeros( img_edit.shape )</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过图片像素相减提取hint</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line">idx = (np.<span class="built_in">abs</span>((img_in-img_edit).<span class="built_in">sum</span>(<span class="number">2</span>)) &gt; <span class="number">1e-4</span>)</span><br><span class="line">img_hint[ idx ] = img_edit[ idx ]</span><br></pre></td></tr></table></figure>
<ul>
<li><code>Image.open()</code>：返回一个image的对象(shape=(w,h))<ul>
<li><code>Image.open().convert(&quot;RGB&quot;)</code>：返回一个image的RGB对象(shape=(w,h,c))</li>
</ul>
</li>
<li><code>sum(n)</code>：沿n维的sum</li>
</ul>
<h3 id="生成稀疏矩阵A"><a href="#生成稀疏矩阵A" class="headerlink" title="生成稀疏矩阵A"></a>生成稀疏矩阵A</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Create the optimization problem</span></span><br><span class="line">w = img_edit.shape[<span class="number">0</span>]</span><br><span class="line">h = img_edit.shape[<span class="number">1</span>]</span><br><span class="line"><span class="comment"># window size</span></span><br><span class="line">wpx = <span class="number">1</span> </span><br><span class="line"><span class="comment"># u和v：只放入已确定颜色的像素id的uv值</span></span><br><span class="line">b_u = np.zeros( (w*h,) )</span><br><span class="line">b_v = b_u.copy()</span><br><span class="line"><span class="comment"># Sparse matrix，一对(row,col)代表一对邻居关系的像素，dat内存储权重</span></span><br><span class="line">row = []</span><br><span class="line">col = []</span><br><span class="line">dat = []</span><br><span class="line"></span><br><span class="line"><span class="comment"># 遍历 w * h = n</span></span><br><span class="line"><span class="keyword">for</span> v <span class="keyword">in</span> <span class="built_in">range</span>(h):</span><br><span class="line">    <span class="keyword">for</span> u <span class="keyword">in</span> <span class="built_in">range</span>(w):</span><br><span class="line">        <span class="comment"># （w，v）to index</span></span><br><span class="line">        i = v*w + u</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Add first entry U(r) for both  channels</span></span><br><span class="line">        <span class="comment"># 像素本身等于自身，因此稀疏矩阵A的对角均为1</span></span><br><span class="line">        row.append( i )</span><br><span class="line">        col.append( i )</span><br><span class="line">        dat.append( <span class="number">1.</span> )</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Skip coloured areas,</span></span><br><span class="line">        <span class="comment"># 已经在给的hint里上色的区域就跳过</span></span><br><span class="line">        <span class="keyword">if</span> idx[u,v]:</span><br><span class="line">            b_u[i] = img_edit[u,v,<span class="number">1</span>]</span><br><span class="line">            b_v[i] = img_edit[u,v,<span class="number">2</span>]</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 求r的neighbour范围</span></span><br><span class="line">        umin = <span class="built_in">max</span>(<span class="number">0</span>,u-wpx)</span><br><span class="line">        umax = <span class="built_in">min</span>(w,u+wpx+<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        vmin = <span class="built_in">max</span>(<span class="number">0</span>,v-wpx)</span><br><span class="line">        vmax = <span class="built_in">min</span>(h,v+wpx+<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 求neighbour范围内的variance</span></span><br><span class="line">        patch = img_in[ umin:umax, vmin:vmax, <span class="number">0</span> ]</span><br><span class="line">        mu_r = np.mean( patch )</span><br><span class="line">        sigma_r = np.var( patch )</span><br><span class="line">        sigma_r = <span class="built_in">max</span>( sigma_r, <span class="number">1e-6</span> )</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 求r的Y</span></span><br><span class="line">        Yr = img_in[u,v,<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Go over neighbours</span></span><br><span class="line">        <span class="comment"># 遍历neighbour，求各自的w</span></span><br><span class="line">        N = []</span><br><span class="line">        wrs = []</span><br><span class="line">        <span class="keyword">for</span> nu <span class="keyword">in</span> <span class="built_in">range</span>( umin, umax ):</span><br><span class="line">            <span class="keyword">for</span> nv <span class="keyword">in</span> <span class="built_in">range</span>( vmin, vmax ):</span><br><span class="line">                j = nv*w + nu</span><br><span class="line">                <span class="keyword">if</span> i==j:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                Ys = img_in[nu,nv,<span class="number">0</span>]</span><br><span class="line">                wrs.append(np.exp(-<span class="number">1</span>*(Yr-Ys)*(Yr-Ys)/ <span class="number">2</span> / sigma_r))</span><br><span class="line">                N.append(j)</span><br><span class="line">        wrs = np.array( wrs )</span><br><span class="line">        <span class="comment"># 对w的约束条件：和必须为1</span></span><br><span class="line">        wrs /= wrs.<span class="built_in">sum</span>()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 根据求出的w完善矩阵</span></span><br><span class="line">        <span class="keyword">for</span> k,j <span class="keyword">in</span> <span class="built_in">enumerate</span>(N):</span><br><span class="line">            row.append(i)</span><br><span class="line">            col.append(j)</span><br><span class="line">            dat.append(wrs[k])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 最终生成一个大小为(wh,wh)的，包含所有点与点之间的权重的矩阵</span></span><br><span class="line">A = csr_matrix( (dat, (row,col)) )</span><br></pre></td></tr></table></figure>
<ul>
<li><code>csr_matrix( (data, (row_index,col_index)) )</code>:  <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">csr_matrix( ([<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>], ([<span class="number">1</span>,<span class="number">3</span>,<span class="number">3</span>],[<span class="number">0</span>,<span class="number">1</span>,<span class="number">3</span>])) ).toarray()</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>array([[<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">   [<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">   [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">   [<span class="number">0</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>]], dtype=int64)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="解方程组生成目标图像"><a href="#解方程组生成目标图像" class="headerlink" title="解方程组生成目标图像"></a>解方程组生成目标图像</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Solve the optimization and display results</span></span><br><span class="line">Y = img_in[:,:,<span class="number">0</span>:<span class="number">1</span>]</span><br><span class="line">U = spsolve(A, b_u).reshape( h, w, <span class="number">1</span> ).transpose( (<span class="number">1</span>,<span class="number">0</span>,<span class="number">2</span>) )</span><br><span class="line">V = spsolve(A, b_v).reshape( h, w, <span class="number">1</span> ).transpose( (<span class="number">1</span>,<span class="number">0</span>,<span class="number">2</span>) )</span><br><span class="line"></span><br><span class="line">img_out = np.concatenate( (Y,U,V), axis=<span class="number">2</span> )</span><br><span class="line">plt.imshow( color.yuv2rgb(img_out) )</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>study</category>
      </categories>
      <tags>
        <tag>optimization</tag>
      </tags>
  </entry>
  <entry>
    <title>HexoTags</title>
    <url>/2022/05/05/HexoTags/</url>
    <content><![CDATA[<h2 id="Note"><a href="#Note" class="headerlink" title="Note"></a>Note</h2><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">&#123;% note [class]%&#125;</span><br><span class="line">Any content (support inline tags too.io).</span><br><span class="line">&#123;% endnote %&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>空白</li>
<li>default</li>
<li>primary</li>
<li>success</li>
<li>info</li>
<li>warning</li>
<li>danger</li>
</ul>
<h2 id="Mermaid"><a href="#Mermaid" class="headerlink" title="Mermaid"></a>Mermaid</h2><div class="note modern"><p>使用mermaid标籤可以绘製Flowchart（流程图）、Sequence diagram（时序图 ）、Class Diagram（类别图）、State Diagram（状态图）、Gantt（甘特图）和Pie Chart（圆形图），具体可以查看<a href="https://mermaid-js.github.io/mermaid/#/">Mermaide文档</a></p>
</div>
<h2 id="Tabs"><a href="#Tabs" class="headerlink" title="Tabs"></a>Tabs</h2><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">&#123;% tabs test1 %&#125;</span><br><span class="line">&lt;!-- tab --&gt;</span><br><span class="line"><span class="strong">**This is Tab 1.**</span></span><br><span class="line">&lt;!-- endtab --&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- tab --&gt;</span><br><span class="line"><span class="strong">**This is Tab 2.**</span></span><br><span class="line">&lt;!-- endtab --&gt;</span><br></pre></td></tr></table></figure>
<div class="tabs" id="test1"><ul class="nav-tabs"><li class="tab active"><button type="button" data-href="#test1-1">表格1</button></li><li class="tab"><button type="button" data-href="#test1-2">表格2</button></li></ul><div class="tab-contents"><div class="tab-item-content active" id="test1-1"><p>这是1</p><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="test1-2"><p>这是2</p><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div></div></div>
<h2 id="label"><a href="#label" class="headerlink" title="label"></a>label</h2><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">&#123;% label 我是 %&#125;&#123;% label 什么 blue %&#125;&#123;%label 颜色 red %&#125;</span><br></pre></td></tr></table></figure>
<mark class="hl-label default">我是</mark> <mark class="hl-label blue">什么</mark> <mark class="hl-label red">颜色</mark> 
]]></content>
      <categories>
        <category>study</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>PRML</title>
    <url>/2022/05/05/PRML/</url>
    <content><![CDATA[<h1 id="Pattern-recognition-and-machine-learning"><a href="#Pattern-recognition-and-machine-learning" class="headerlink" title="Pattern recognition and machine learning"></a>Pattern recognition and machine learning</h1><h2 id="0-Guidance"><a href="#0-Guidance" class="headerlink" title="0. Guidance"></a>0. Guidance</h2><ul>
<li>English<ol>
<li>neural network  </li>
<li>in the past decade</li>
<li>achieve breakthrough　取得重大进展</li>
<li>speech recognition 语音识别</li>
<li>machine translation 机器翻译</li>
<li>train CNN from scratch 从零开始训练</li>
<li>afterwards 之后</li>
<li>ambiguous 不明确的</li>
<li>classes to be recognized 将要被识别的类</li>
<li>estimate 评价</li>
<li>supplemental 补充的</li>
<li>proceed 继续</li>
</ol>
</li>
</ul>
<h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h2><ul>
<li>English<ol>
<li>contribute to 造成；以助于</li>
<li>emphasize 强调</li>
<li>tough 难的</li>
<li>facility 能力</li>
<li>prebuilt 做好的</li>
</ol>
</li>
</ul>
<blockquote>
<p>Perceptual computing in auttumn is advanced content of RP</p>
</blockquote>
<h3 id="1-1-what-is-PR"><a href="#1-1-what-is-PR" class="headerlink" title="1.1 what is PR"></a>1.1 what is PR</h3><ul>
<li>Problem/target of PR:<strong>How to estimate the class of data?</strong></li>
<li><p>Method / Procedure of PR</p>
<ol>
<li>prepare training data(labeled)</li>
<li>get feature vectors from data</li>
<li>get distribution of each class from feature vectors</li>
<li>get distribution of each class</li>
<li>define class boudary </li>
<li><p>estimate class</p>
<p>❓What is difference between PR and classification</p>
</li>
</ol>
<ul>
<li><p>Pattern recognition is a generic term for the ability to recognize regularities or patterns in data. A more generic one is machine learning. Classification is an example of pattern recognition, where a model devides the data into classes.</p>
<p>  More specific from left to right: <strong><em>Machine Learning &gt; Pattern Recognition &gt; Classification &gt; Linear Classification &gt; SVM</em></strong></p>
</li>
</ul>
</li>
</ul>
<h3 id="SV1-2-Data-driven-feature-extraction"><a href="#SV1-2-Data-driven-feature-extraction" class="headerlink" title="SV1-2 Data-driven feature extraction"></a>SV1-2 Data-driven feature extraction</h3><ul>
<li>English<ol>
<li>wind turbine 风轮机</li>
<li>anomaly detection 异常检出</li>
<li>large- scale 大规模的</li>
<li>feasible 可能的，可行的 《=》 infeasible</li>
<li>adhoc video search 特别录像查询（whether the queried object is shown in video or not）</li>
<li>-driven 由…主导的<ol>
<li>data-driven 数据驱动的</li>
</ol>
</li>
<li>discriminative model 識別モデル</li>
<li>be suitable to 适合于</li>
<li>CMS：Condition Monitoring System</li>
<li>GMM:Gaussian Mixture Model</li>
<li></li>
</ol>
</li>
<li>If we don’t have enough data to train a network when we know it’s similar to another task, we can:  use the <strong>well-developed NN for feature extractor    →</strong> so we can only trian <strong>a part of NN by fewer train data</strong></li>
<li><p>Anomaly  detection APPROACH</p>
<ol>
<li><p>Auto encoder (AE)</p>
<blockquote>
<p>エンコードしてからデコードします　→　次元削減、特徴抽出</p>
<ul>
<li>教師なし学習、異常データいらない</li>
<li>仕組み：デコードの時に再構築するため、学習されていないものが元画像とのlossがめちゃくちゃ高くなり、Acnomalyと判定される。<a href="http://www.renom.jp/ja/notebooks/tutorial/clustering/anomaly-detection-using-autoencoder/notebook.html">http://www.renom.jp/ja/notebooks/tutorial/clustering/anomaly-detection-using-autoencoder/notebook.html</a></li>
<li>Need a great number of Traing DATASET</li>
</ul>
</blockquote>
<pre><code> ![截屏2022-04-06 15.31.18.png](Pattern%20recognition%20and%20machine%20learning%20e1f94fd17812467f8adc1a323302ed35/%E6%88%AA%E5%B1%8F2022-04-06_15.31.18.png)

 ![截屏2022-04-06 15.33.26.png](Pattern%20recognition%20and%20machine%20learning%20e1f94fd17812467f8adc1a323302ed35/%E6%88%AA%E5%B1%8F2022-04-06_15.33.26.png)
</code></pre></li>
<li><p>DNN (discriminative feature extractor)</p>
<ul>
<li><p>need to input <strong>normal data and abnoormal data</strong> to train the model how to discriminate</p>
<p>  <img src="Pattern%20recognition%20and%20machine%20learning%20e1f94fd17812467f8adc1a323302ed35/%E6%88%AA%E5%B1%8F2022-04-06_15.33.00.png" alt="截屏2022-04-06 15.33.00.png"></p>
<p>  <img src="Pattern%20recognition%20and%20machine%20learning%20e1f94fd17812467f8adc1a323302ed35/%E6%88%AA%E5%B1%8F2022-04-06_15.33.37.png" alt="截屏2022-04-06 15.33.37.png"></p>
</li>
</ul>
</li>
</ol>
</li>
</ul>
<h3 id="SV2-Semi-supervised-learning"><a href="#SV2-Semi-supervised-learning" class="headerlink" title="SV2 Semi-supervised learning"></a>SV2 Semi-supervised learning</h3><ul>
<li>English<ul>
<li>assign labels ラベルを付与する</li>
<li>supervised 教師あり</li>
<li>semi-supervised 半教師あり</li>
<li>unsupervised 教師なし</li>
<li>reliable-unreliable 可靠的 - 不可靠的</li>
<li>exploit 利用</li>
<li>in terms of 就。。。而言,从。。。观点来看</li>
<li>engage 使参与；吸引；雇佣</li>
<li>refer to 称之为</li>
<li>calve 产子</li>
<li>exploision 爆炸；突然出现</li>
<li>sophisticate 使更精确</li>
<li>threshold 下限；门槛</li>
<li>intermidiate 中距离</li>
<li>rotation 旋转</li>
<li>assimilation 同化，融合</li>
</ul>
</li>
<li><p>Semi-supervise</p>
<p>  <img src="Pattern%20recognition%20and%20machine%20learning%20e1f94fd17812467f8adc1a323302ed35/%E6%88%AA%E5%B1%8F2022-04-06_15.50.55.png" alt="截屏2022-04-06 15.50.55.png"></p>
</li>
<li><p>crowdsourcing</p>
<p>  Request tasks to unspecified large number of people</p>
<p>  (E.g. To let them annotation the object(迷惑メール))</p>
</li>
</ul>
<h3 id="SV3-Data-assimilation"><a href="#SV3-Data-assimilation" class="headerlink" title="SV3 Data assimilation"></a>SV3 Data assimilation</h3><ul>
<li>English<ul>
<li>oceangraphical 海洋学的</li>
<li>incorporate 纳入；合并</li>
<li>in contrast 相反的</li>
<li>operation 运行，实施，行动</li>
<li>meteorological 气象学的</li>
<li>intuition 直觉</li>
<li>consist of 包括</li>
<li>induce 劝说，促使</li>
<li>influx 流入 涌入</li>
<li>pot 笼子</li>
<li>emulate 模仿 仿真</li>
<li>sophiscated 需要经验的</li>
<li>stochastic 随机的</li>
<li>fomulation 构想；体系化，公式化</li>
<li>state equation 状态方程式</li>
<li>observation equation 观测方程式</li>
<li>degree 程度，阶段</li>
<li>dotted line 虚线</li>
<li>phenomenon 现象</li>
</ul>
</li>
<li>Data Assimilation(データ同化、数据同化)<ul>
<li>主に<a href="https://ja.wikipedia.org/wiki/%E5%9C%B0%E7%90%83%E7%A7%91%E5%AD%A6">地球科学</a>の分野において数値<a href="https://ja.wikipedia.org/wiki/%E6%95%B0%E7%90%86%E3%83%A2%E3%83%87%E3%83%AB">モデル</a>の再現性を高めるために行われる作業である。簡単に言えば、モデルに実際の観測値を入力してより現実に近い結果が出るようにすることを指す。</li>
</ul>
</li>
<li>GBDT<ul>
<li>GBDTとは「勾配降下法(Gradient)」と「Boosting(アンサンブル)」、「決定木(Decision Tree)」を組み合わせた手法です。</li>
</ul>
</li>
</ul>
<blockquote>
<p>In this case (for forcasting the fish catchs), we get better result in DATA ASSIMILATION but not machine learning .<br>Because we can’t deal with data that not happend in the previous data<br>But in DA,we can incorporate expert’s knowledge when make a model so it can predict very well although we only have a few of data</p>
</blockquote>
<h3 id="Summarize"><a href="#Summarize" class="headerlink" title="Summarize"></a>Summarize</h3><p><img src="Pattern%20recognition%20and%20machine%20learning%20e1f94fd17812467f8adc1a323302ed35/%E6%88%AA%E5%B1%8F2022-04-07_17.54.35.png" alt="截屏2022-04-07 17.54.35.png"></p>
<h2 id="2-Feature-embedding"><a href="#2-Feature-embedding" class="headerlink" title="2. Feature embedding"></a>2. Feature embedding</h2><ul>
<li>English<ul>
<li>dimensionality reduction 次元削減</li>
<li>coordinate 座標</li>
<li>orthonormal coordinate 正規系座標系</li>
<li>basis 基底</li>
<li>subspace 部分空間</li>
<li>projection function 射影変換</li>
<li>Principal Component Analysis 主成分分析</li>
<li>prime　プライム；上标号</li>
<li>scatter 分散，散布</li>
<li>axis 轴</li>
<li>formulate 构想，创建，表达</li>
<li>notation memo</li>
<li>constraint 限制</li>
<li>derivative 导数</li>
<li>eigenvalue 固有值</li>
<li>eigenvector 固有向量</li>
<li>correspond 相符，相当</li>
<li>consistent 一致的</li>
</ul>
</li>
</ul>
<h3 id="Dimensionality-Reduction"><a href="#Dimensionality-Reduction" class="headerlink" title="Dimensionality Reduction"></a>Dimensionality Reduction</h3><p><strong>Goal: Reduct dimensions but minimize the loss of information</strong></p>
<p><img src="Pattern%20recognition%20and%20machine%20learning%20e1f94fd17812467f8adc1a323302ed35/%E6%88%AA%E5%B1%8F2022-04-08_16.36.37.png" alt="截屏2022-04-08 16.36.37.png"></p>
<p><img src="Pattern%20recognition%20and%20machine%20learning%20e1f94fd17812467f8adc1a323302ed35/%E6%88%AA%E5%B1%8F2022-04-08_16.37.05.png" alt="截屏2022-04-08 16.37.05.png"></p>
<p>T : a projection function</p>
<p>x: data will to be reducted</p>
<p>z: reducted data</p>
<h3 id="Principal-Component-Analysis-PCA"><a href="#Principal-Component-Analysis-PCA" class="headerlink" title="Principal Component Analysis(PCA)"></a>Principal Component Analysis(PCA)</h3><ul>
<li><p>Minimum Loss of Information = Maximum Variance</p>
<p>  <img src="Pattern%20recognition%20and%20machine%20learning%20e1f94fd17812467f8adc1a323302ed35/%E6%88%AA%E5%B1%8F2022-04-08_17.00.14.png" alt="截屏2022-04-08 17.00.14.png"></p>
<p>  OA is a constant → Minimize error AA’ = Maximize variance OA’</p>
<pre><code>                              → Sum of errors over all samples would be     
</code></pre><p>  minimized.= Variance of all projected samples on subspace<br>  would be maximized.</p>
</li>
<li><p>検証</p>
<p>  <img src="Pattern%20recognition%20and%20machine%20learning%20e1f94fd17812467f8adc1a323302ed35/Untitled.png" alt="Untitled"></p>
<p>   **射影の分散の平均値を0としています</p>
</li>
<li><p>手順：</p>
<ol>
<li>sample x の分散共分散行列求める</li>
<li>固有値、固有ベクトル求める</li>
<li>固有値の絶対値大きいほど、大きい分散しているを表す。対応のベクトルは第一成分。</li>
</ol>
</li>
<li><p>評価方法</p>
<ul>
<li><p>寄与率</p>
<p>  <img src="Pattern%20recognition%20and%20machine%20learning%20e1f94fd17812467f8adc1a323302ed35/%E6%88%AA%E5%B1%8F2022-04-11_15.30.44.png" alt="截屏2022-04-11 15.30.44.png"></p>
</li>
<li><p>累積寄与率</p>
<p>  <img src="Pattern%20recognition%20and%20machine%20learning%20e1f94fd17812467f8adc1a323302ed35/%E6%88%AA%E5%B1%8F2022-04-11_15.31.50.png" alt="截屏2022-04-11 15.31.50.png"></p>
</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>study</category>
      </categories>
      <tags>
        <tag>PR</tag>
      </tags>
  </entry>
  <entry>
    <title>凸优化问题</title>
    <url>/2022/05/06/%E5%87%B8%E4%BC%98%E5%8C%96%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<script type="math/tex; mode=display">\text{minimize }f_0(x)</script><script type="math/tex; mode=display">\text{subject to } f_i(x)\le 0, i=1...m</script><script type="math/tex; mode=display">h(x)=0, i=1...p</script><ul>
<li>目标函数(objective f)必须为凸(convex)</li>
<li>不等式(inequality constraint f)约束函数必须为凸</li>
<li>等式约束函数必须为仿射(affine)</li>
<li>定义域是m个凸的下水平集($f_i(x)$)和p个超平面($h(x)$)的交集</li>
<li>我们其实是在一个凸集上极小化一个凸的目标函数</li>
<li>局部最优解自动成为全局最优解</li>
</ul>
<h2 id="最优值与最优解-optimal-value-and-optimal-point"><a href="#最优值与最优解-optimal-value-and-optimal-point" class="headerlink" title="最优值与最优解 optimal value and optimal point"></a>最优值与最优解 optimal value and optimal point</h2><div class="note warning modern"><p>最优值为最优解对应的y值</p>
</div>
<p><strong>最优值</strong>定义为</p>
<script type="math/tex; mode=display">p^*=inf\{f_0(x)|满足约束条件\}</script><ul>
<li>当没有可行点（没有点满足约束条件）时，p为不可行（infeasible）且等于$\infty$</li>
<li>如果$p^*=-\infty$，则称这个问题无下界（unbounded below）</li>
</ul>
<p>当$x^{*}$可行并且$f_0(x^*)=p^{*}$时称之为<strong>最优解</strong></p>
]]></content>
      <categories>
        <category>study</category>
      </categories>
      <tags>
        <tag>optimization</tag>
      </tags>
  </entry>
  <entry>
    <title>凸集合与凸函数</title>
    <url>/2022/05/06/%E5%87%B8%E9%9B%86%E5%90%88%E4%B8%8E%E5%87%B8%E5%87%BD%E6%95%B0/</url>
    <content><![CDATA[<h2 id="1-convex-sets"><a href="#1-convex-sets" class="headerlink" title="1. convex sets"></a>1. convex sets</h2><h3 id="1-1-Line-segmentation-直线分割"><a href="#1-1-Line-segmentation-直线分割" class="headerlink" title="1.1 Line segmentation 直线分割"></a>1.1 Line segmentation 直线分割</h3><script type="math/tex; mode=display">y=\theta x_1+(1-\theta)x_2</script><script type="math/tex; mode=display">y=x_2+\theta(x_1-x_2)</script><blockquote>
<p>$\theta$=1时$y=x_1$,=0时反之，所以称为<strong>直线分割 </strong></p>
<p>根据式2也可以看做是以x_2为基准。向x_1-x_2延伸的一条线<br><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h1ykewxdwij208m048q2r.jpg" alt=""></p>
</blockquote>
<h3 id="1-2-affine-sets"><a href="#1-2-affine-sets" class="headerlink" title="1.2 affine sets"></a>1.2 affine sets</h3><p>仿射集C上的任意两点连成的直线属于C<br>即</p>
<script type="math/tex; mode=display">{\theta x_{1}+(1-\theta) x_{2} \in C, \quad \forall x_{1}, x_{2} \in C, \text { and } \theta \in \mathbb{R}}</script><p>扩展到多点上为</p>
<script type="math/tex; mode=display">x_1, x_2 ... x_k \in C</script><script type="math/tex; mode=display">\bf{AND} {\theta}_1+{\theta}_2+...+{\theta}_k=1</script><script type="math/tex; mode=display">\bf{THEN} \theta x_{1}+...+\theta_k x_{k} \in C</script><p>其中，对于属于C的子空间是<br>$V=C-x_0=\{x-x_0|x\in C\}$</p>
<blockquote>
<p>意味着标量乘积之和是闭合的</p>
</blockquote>
<p>子空间维数=仿射集维数</p>
<h3 id="1-3-affine-hull-仿射包"><a href="#1-3-affine-hull-仿射包" class="headerlink" title="1.3 affine hull 仿射包"></a>1.3 affine hull 仿射包</h3><p>aff$C=\{\theta x_{1}+…+\theta_k x_{k}|x_{1}, x_{2}…x_k\in C, \theta_1+\theta_2+…+\theta_k=1\}$</p>
<ol>
<li>C中的所有点的仿射组合组成的集合</li>
<li>仿射集维数=仿射集子空间的维数</li>
<li>是包含C的最小仿射集合</li>
</ol>
<h3 id="1-4-相对内部-relative-interior"><a href="#1-4-相对内部-relative-interior" class="headerlink" title="1.4 相对内部 relative interior"></a>1.4 相对内部 relative interior</h3><p>如果集合C的仿射维数小于n,那么aff$C\ne R ^n$<br>相对内部relint C定义为<br>$\text { relint } C =\{x \in C \mid B(x, r) \cap \operatorname{aff} C \subseteq C \text { for some } r&gt;0\}$<br>其中$B(x,y)=\{y| |y-x|\le r\}$(任意范数均可)</p>
<blockquote>
<p>（呃呃呃开始不说人话了是吧）</p>
</blockquote>
<h3 id="1-5-convex-sets-凸集"><a href="#1-5-convex-sets-凸集" class="headerlink" title="1.5 convex sets 凸集"></a>1.5 convex sets 凸集</h3><p>任意两点的线段都在C中<br>$\theta x_{1}+(1-\theta) x_{2} \in C$<br><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h1ym9ddkmrj21610aata5.jpg" alt=""><br>所有点的凸组合为凸包（convex hull）<br>conv$C=\{\theta x_{1}+…+\theta_k x_{k}|x_{1}, x_{2}…x_k\in C, \theta_1+\theta_2+…+\theta_k=1, \theta_i\ge 0\}$<br>凸包是包含C的最小凸集<br><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h1ym9epnp9j216e0b3jsg.jpg" alt=""></p>
<h2 id="2-cone-锥"><a href="#2-cone-锥" class="headerlink" title="2. cone 锥"></a>2. cone 锥</h2><p>对与任何x属于C以及$\theta$大于等于0，都有<br>$\theta x\in C$</p>
<h3 id="2-1-凸锥"><a href="#2-1-凸锥" class="headerlink" title="2.1 凸锥"></a>2.1 凸锥</h3><p>锥且凸，即<br>$\theta_1 x_1 + \theta_2 x_2\in C$<br><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h1yme7l34kj21650iddhe.jpg" alt=""></p>
<h3 id="2-2-锥包"><a href="#2-2-锥包" class="headerlink" title="2.2 锥包"></a>2.2 锥包</h3><p>所有锥组合形成的集合</p>
<h2 id="3-重要例子"><a href="#3-重要例子" class="headerlink" title="3. 重要例子"></a>3. 重要例子</h2><h3 id="3-1-一些概念"><a href="#3-1-一些概念" class="headerlink" title="3.1 一些概念"></a>3.1 一些概念</h3><ol>
<li>空集、任意一个点（即单点集）、全空间R”都是Rn的仿射（自然也是凸的)子集。</li>
<li>任意直线是仿射的。如果直线通过零点，则是子空间，因此，也是凸锥。</li>
<li>一条线段是凸的，但不是仿射的（除非退化为一个点）。</li>
<li>一条射线，即具有形式$\{x_0+\theta v|\theta≥0\}$，v≠0的集合，是凸的，但不是仿射的。如果射线的基点$x_0$是0，则它是凸锥。</li>
<li>任意子空间是仿射的、凸锥（自然是凸的）。</li>
</ol>
<h3 id="3-2-超平面"><a href="#3-2-超平面" class="headerlink" title="3.2 超平面"></a>3.2 超平面</h3><p>$\{x|a^Tx=b\}$</p>
<ul>
<li>$a\in R^n且不为0, b\in R$</li>
<li>超平面是关于x的线性方程的解空间（因此是仿射集合）</li>
</ul>
<h3 id="3-3-半空间"><a href="#3-3-半空间" class="headerlink" title="3.3 半空间"></a>3.3 半空间</h3><p>$\{x|a^Tx\le b\}$</p>
<ul>
<li>线性不等式的解空间</li>
<li>凸但不仿射</li>
<li>由超平面切割而成2个半空间</li>
</ul>
<h3 id="3-4-Euclid球"><a href="#3-4-Euclid球" class="headerlink" title="3.4 Euclid球"></a>3.4 Euclid球</h3><p>$\begin{aligned}<br>B\left(x_{c}, r\right) &amp;=\left\{x \mid\left|x-x_{c}\right|_{2} \leq r\right\} \\<br>&amp;=\left\{x \mid\left(x-x_{c}\right)^{\top}\left(x-x_{c}\right) \leq r^{2}\right\}<br>\end{aligned}$</p>
<ul>
<li>$x_c$为球心</li>
<li>r是半径</li>
</ul>
<h3 id="3-5-多面体"><a href="#3-5-多面体" class="headerlink" title="3.5 多面体"></a>3.5 多面体</h3><p>$\begin{array}{r}<br>\mathcal{P}=\left\{x \mid a_{j}^{\top} x-b_{j} \leq 0, j=1, \ldots, m\right. \\<br>\left.c_{j}^{\top} x-d_{j}=0, j=1, \ldots, p\right\}<br>\end{array}$</p>
<ul>
<li>有限个线性等式和不等式的集合（即有限个超平面和半空间的交集）</li>
<li>凸集</li>
</ul>
<h2 id="4-凸集间的保凸运算"><a href="#4-凸集间的保凸运算" class="headerlink" title="4. 凸集间的保凸运算"></a>4. 凸集间的保凸运算</h2><p>凸集之间的运算生成新的凸集</p>
<h3 id="4-1-交集"><a href="#4-1-交集" class="headerlink" title="4.1 交集"></a>4.1 交集</h3><p>$S=S1 \cap S2 $也为凸</p>
<h3 id="4-2-仿射函数"><a href="#4-2-仿射函数" class="headerlink" title="4.2 仿射函数"></a>4.2 仿射函数</h3><p>形同$f(x)=Ax+b$，对于任意点s属于凸集S，$f(s)$为凸<br>同样若有f(s)属于凸集S，则原象$f^{-1}(s)$也为凸</p>
<h3 id="4-3-透视函数"><a href="#4-3-透视函数" class="headerlink" title="4.3 透视函数"></a>4.3 透视函数</h3><p>对于$P(z,t)=z/t$（定义域为dom $P=R^n \times R_{++}$ ）</p>
<blockquote>
<p>$R_{++}为正实数$</p>
</blockquote>
<p>则对任意x属于凸C，P(x)也为凸</p>
<h2 id="5-凸函数"><a href="#5-凸函数" class="headerlink" title="5. 凸函数"></a>5. 凸函数</h2><p>$f:R^n \rightarrow R$, 若dom f为凸集，且x,y属于dom f,且$\theta$在0，1之间，则</p>
<script type="math/tex; mode=display">f(\theta x+(1-\theta) y) \leq \theta f(x)+(1-\theta) f(y)</script><ul>
<li>严格凸函数：无等号</li>
<li>凹函数：当-f是凸</li>
</ul>
<p>最大值函数就是一个凸函数：<br><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h1yqclyw6ij20r207uq3i.jpg" alt=""></p>
<h3 id="5-1-扩展值延伸-Extended-value-extensions"><a href="#5-1-扩展值延伸-Extended-value-extensions" class="headerlink" title="5.1 扩展值延伸 Extended-value extensions"></a>5.1 扩展值延伸 Extended-value extensions</h3><p>定义：当x不在dom f时，我们认为$f(x)=\infty$</p>
<h3 id="5-2-一阶条件"><a href="#5-2-一阶条件" class="headerlink" title="5.2 一阶条件"></a>5.2 一阶条件</h3><ol>
<li>dom f是凸集</li>
<li>$f(y)\ge f(x)+ \bigtriangledown f(x)^T(y-x) $</li>
</ol>
<ul>
<li>右式为f在点x附近的泰勒近似</li>
</ul>
<h3 id="5-3-二阶条件"><a href="#5-3-二阶条件" class="headerlink" title="5.3 二阶条件"></a>5.3 二阶条件</h3><p>$f(x)$的hessian矩阵为半正定，即可认为</p>
<script type="math/tex; mode=display">\bigtriangledown^2f(x) \succeq 0</script><blockquote>
<p>$\succeq$指的是矩阵中的不等式</p>
</blockquote>
<ul>
<li>对于在R上的f，我们简单的认为就是二阶导大于等于0</li>
</ul>
<h3 id="5-4-凸函数间的保凸运算"><a href="#5-4-凸函数间的保凸运算" class="headerlink" title="5.4 凸函数间的保凸运算"></a>5.4 凸函数间的保凸运算</h3><ul>
<li><p>非负加权求和</p>
<script type="math/tex; mode=display">f=w_1f_1+w_2f_2+...+w_kf_k(w非负，f凸函数)</script></li>
<li><p>复合仿射映射</p>
<script type="math/tex; mode=display">g(x)=f(Ax+b)</script><p>f凸时，g凸</p>
</li>
</ul>
]]></content>
      <categories>
        <category>study</category>
      </categories>
      <tags>
        <tag>optimization</tag>
      </tags>
  </entry>
  <entry>
    <title>无约束最优化</title>
    <url>/2022/05/04/%E6%97%A0%E7%BA%A6%E6%9D%9F%E6%9C%80%E4%BC%98%E5%8C%96/</url>
    <content><![CDATA[<h2 id="1-Minizer"><a href="#1-Minizer" class="headerlink" title="1. Minizer"></a>1. Minizer</h2><ol>
<li>全局最小值 Global Minizer</li>
<li>局部最小值 Local Minizer<ul>
<li>weak </li>
<li>strict</li>
<li>孤立的局部最小值isolated local minimizer <div class="note success modern"><p>对于凸函数，局部最小值立即成为全局最小值</p>
</div>
</li>
</ul>
</li>
</ol>
<h2 id="2-局部最小值条件"><a href="#2-局部最小值条件" class="headerlink" title="2. 局部最小值条件"></a>2. 局部最小值条件</h2><ol>
<li>一阶必要条件（FIRST-ORDER NECESSARY CONDITIONS）<ol>
<li>函数$f(x)$在点$x^*$可微</li>
<li>梯度${\nabla f(x^*)=0}$</li>
</ol>
</li>
<li>二阶必要条件<ol>
<li>满足一阶</li>
<li>hesse矩阵${\nabla^2 f(x^*)}$半正定   </li>
</ol>
</li>
</ol>
<div class="tabs" id="1"><ul class="nav-tabs"><li class="tab active"><button type="button" data-href="#1-1">海塞矩阵</button></li><li class="tab"><button type="button" data-href="#1-2">半正定值</button></li><li class="tab"><button type="button" data-href="#1-3">海塞矩阵的半正定值</button></li></ul><div class="tab-contents"><div class="tab-item-content active" id="1-1"><p><img src="https://ds055uzetaobb.cloudfront.net/brioche/uploads/gVN1lN1A28-hessian.png?width=1200" alt=""></p><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="1-2"><p>半正定值：</p>
<ol>
<li>对于所有x不等于0，都有 ${x^TAx≥0}$</li>
<li>且对某个x不等于0,有 ${x^TAx&gt;0}$</li>
</ol><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="1-3"><p>因为hesse矩阵是对称矩阵所以有以下性质：（仅限于对称矩阵！！）<br>半正定：所有特征值都大于等于0<br>正定：所有特征值都大于0<br>负定：所有特征值都小于0</p><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div></div></div>
<mark class="hl-label red">现在虽然知道了确认某点是否为最小值的算法，但是对于如何找到这个点我们还无从得知（总不能把所有点都算一遍吧）</mark> 
<h2 id="3-直线探索策略-line-search-strategy"><a href="#3-直线探索策略-line-search-strategy" class="headerlink" title="3. 直线探索策略 line search strategy"></a>3. 直线探索策略 line search strategy</h2><ol>
<li>Line Serch<br> 设在某点$x_k$，寻找方向$p_k$和步长$\alpha$使得min$f(x_k+\alpha p_k)$<br> <strong>需求值：方向和步长</strong></li>
<li>Trust Region<br> 对于点x_k上的近似函数求最小值：min$m_k(x_k+p_k)$。同时，近似函数是有限的，所以可信赖区间需要被确定。<br> <strong>需求值：近似函数和可信赖区间p</strong></li>
</ol>
]]></content>
      <categories>
        <category>study</category>
      </categories>
      <tags>
        <tag>optimization</tag>
      </tags>
  </entry>
  <entry>
    <title>最小二乘问题</title>
    <url>/2022/05/05/%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<h2 id="最小二乘（LEAST-SQUARES）问题定义"><a href="#最小二乘（LEAST-SQUARES）问题定义" class="headerlink" title="最小二乘（LEAST-SQUARES）问题定义"></a>最小二乘（LEAST-SQUARES）问题定义</h2><p>${f_0(x)=||Ax-b||^2_2<br>        =\sum_{i=1}^k({a_i}^Tx-b_i)^2}$</p>
<blockquote>
<p>2-范数<br>${||x||_2=(x,x)^{1/2}=\sqrt{\sum_{i=1}^n x_i^2}}$</p>
</blockquote>
<h2 id="最小二乘法"><a href="#最小二乘法" class="headerlink" title="最小二乘法"></a>最小二乘法</h2><p>上面的式子可被简化为：<br>${(A^TA)x = A^Tb}$     →    ${x = (A^TA)^{-1}A^Tb}$<br>代入原式并求hesse矩阵的话<br>${\nabla^2 ||Ax-b||^2_2=2A^TA}$<br>→ 变成了确认 ${2A^TA}$的正定值与否的问题</p>
<h2 id="补充：最小二乘"><a href="#补充：最小二乘" class="headerlink" title="补充：最小二乘"></a>补充：最小二乘</h2><ul>
<li>如下二维平面图中有很多个点，假设我们想用一条直线来拟合数据，即期望能找到一条直线能最好地穿过这些数据点。</li>
<li>一个点就可以构造一个方程，而未知数显然只有两个（直线的斜率和截距），因此这就是一个超定系统，我们是没有办法找到一条完美的直线，使得上述的点都在直线上。因此，我们只能期望找到一条最好的“适配（best fitting line）”直线来拟合这些数据</li>
<li>有x作为自变量，y表示x对应的真实值，$y^hat$表示由拟合直线对应的预测值</li>
<li>找一条直线能使得所有点离这个直线的距离平均值最小的这种近似的结果就是回归分析的目标。</li>
<li>最小二乘法主要包含了两大类方法，一种是线性最小二乘法（Linear Least Squares），一种是非线性最小二乘法（Nonlinear Least Squares）。</li>
</ul>
]]></content>
      <categories>
        <category>study</category>
      </categories>
      <tags>
        <tag>optimization</tag>
      </tags>
  </entry>
  <entry>
    <title>闲谈-关于美术馆拍摄的变形问题</title>
    <url>/2022/05/05/%E9%97%B2%E8%B0%88-%E5%85%B3%E4%BA%8E%E7%BE%8E%E6%9C%AF%E9%A6%86%E6%8B%8D%E6%91%84%E7%9A%84%E5%8F%98%E5%BD%A2%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<p>前几天去艺术馆拍了不少喜欢的画作，本想回来美美做墙纸之类的，结果….<br><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h1xc5rlm0hj213y0u0afo.jpg" alt="除去我摄影水平不够导致的没有完美对齐的问题，和红框相比能明显看出来似乎加了鱼眼效果般突出来了点"></p>
<p><em>除去我摄影水平不够导致的没有完美对齐的问题，和红框相比能明显看出来似乎加了鱼眼效果般突出来了点</em></p>
<h2 id="镜头变形"><a href="#镜头变形" class="headerlink" title="镜头变形"></a>镜头变形</h2><p><img src="https://i.guancha.cn/bbs/2020/06/21/20200621224008407.png?imageView2/2/w/500/format/png" alt="枕形变形与鼓形变形"></p>
<blockquote>
<p>“<em>对于一般的风景画，没有多少直线，对枕形变形不太敏感；但要是以建筑为主体，或者是有较多靠近画框边缘的直线的抽象画，枕形变形就会比较扎眼。如果要把画框拍出来，平直线条紧贴着画面边缘，枕形变形特别容易显出来，佳能红圈20-70/2.8都压不住，慢说任何小数码相机了。这是拍摄绘画的“不利条件”。</em>“</p>
</blockquote>
<h2 id="球差（球面収差）"><a href="#球差（球面収差）" class="headerlink" title="球差（球面収差）"></a>球差（球面収差）</h2><p><img src="http://www.kansmemo.com/archives/001/201009/4c99aa26d1e4d.png" alt=""><br>透过镜头外侧的光和透镜片中心(近轴)附近的光,因为焦点位置不同而产生变形。原理上来说，只要镜头为球面镜头这一现象就不可避免。<br>相反,球面收差可以通过使用适当设计——非球面镜头来消除。所以,最近的镜头中非球面镜头开始被普遍使用。<br><img src="http://www.kansmemo.com/archives/001/201009/4c99aa29663c5.png" alt=""></p>
<h2 id="题外话"><a href="#题外话" class="headerlink" title="题外话"></a>题外话</h2><p>物理学的稀巴烂所以基本还停留在初中学的“凸透镜光线汇聚成一点”，所以其实理解这个费了好大的功夫。一些关于<strong>为什么与教科书不同，凸透镜的焦点并不能完美汇聚于一点</strong>的补充如下：</p>
<blockquote>
<p>聚集到一点，需要几个因素<br>1、理想平行光<br>2、理想凸透镜<br>3、理想单一频率<br>4、理想粒子特性(实际上光具有波粒两相性)</p>
</blockquote>
<p>[1]<a href="https://www.zhihu.com/question/272102579/answer/1297496356">https://www.zhihu.com/question/272102579/answer/1297496356</a><br>[2]<a href="http://www.kansmemo.com/photo/camera/principles/entry-191.html">http://www.kansmemo.com/photo/camera/principles/entry-191.html</a></p>
]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>other</tag>
      </tags>
  </entry>
</search>
